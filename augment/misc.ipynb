{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ytest: [0 1 2 3 4 5]\n",
      "ytrain: [0 1 2 3 4 5]\n",
      "Class distribution in y_test: [3 5 3 3 5 5]\n",
      "Class distribution in y_train: [17 15 17 17 15 15]\n",
      "Augmentation: UnnamedFliplr\n",
      "Class: 0\n",
      "Unique classes test : [0 1 2 3 4 5]\n",
      "Unique classes pred : [0 1 5]\n",
      "Class: 1\n",
      "Unique classes test : [0 1 2 3 4 5]\n",
      "Unique classes pred : [0 5]\n",
      "Class: 2\n",
      "Unique classes test : [0 1 2 3 4 5]\n",
      "Unique classes pred : [0 1 5]\n",
      "Class: 3\n",
      "Unique classes test : [0 1 2 3 4 5]\n",
      "Unique classes pred : [0 1 5]\n",
      "Class: 4\n",
      "Unique classes test : [0 1 2 3 4 5]\n",
      "Unique classes pred : [0 2 5]\n",
      "Class: 5\n",
      "Unique classes test : [0 1 2 3 4 5]\n",
      "Unique classes pred : [0 1 2]\n",
      "Augmentation: UnnamedFlipud\n",
      "Class: 0\n",
      "Unique classes test : [0 1 2 3 4 5]\n",
      "Unique classes pred : [0 1 5]\n",
      "Class: 1\n",
      "Unique classes test : [0 1 2 3 4 5]\n",
      "Unique classes pred : [0 1 5]\n",
      "Class: 2\n",
      "Unique classes test : [0 1 2 3 4 5]\n",
      "Unique classes pred : [0 1 5]\n",
      "Class: 3\n",
      "Unique classes test : [0 1 2 3 4 5]\n",
      "Unique classes pred : [0 1 5]\n",
      "Class: 4\n",
      "Unique classes test : [0 1 2 3 4 5]\n",
      "Unique classes pred : [0 1 5]\n",
      "Class: 5\n",
      "Unique classes test : [0 1 2 3 4 5]\n",
      "Unique classes pred : [0 1 5]\n",
      "Augmentation: UnnamedMultiply\n",
      "Class: 0\n",
      "Unique classes test : [0 1 2 3 4 5]\n",
      "Unique classes pred : [0 2 3 4]\n",
      "Class: 1\n",
      "Unique classes test : [0 1 2 3 4 5]\n",
      "Unique classes pred : [0 1 5]\n",
      "Class: 2\n",
      "Unique classes test : [0 1 2 3 4 5]\n",
      "Unique classes pred : [0 1 2 4 5]\n",
      "Class: 3\n",
      "Unique classes test : [0 1 2 3 4 5]\n",
      "Unique classes pred : [0 1 2 3 5]\n",
      "Class: 4\n",
      "Unique classes test : [0 1 2 3 4 5]\n",
      "Unique classes pred : [0 1 2 3 4 5]\n",
      "Class: 5\n",
      "Unique classes test : [0 1 2 3 4 5]\n",
      "Unique classes pred : [1 2 3 4 5]\n",
      "########################################\n",
      "\n",
      "Augmentation:  == UnnamedFliplr ==\n",
      "\n",
      "========================================\n",
      "Class Class_0 Classification Report:\n",
      "metric: Class_0, class_label: Class_0\n",
      "0: {'precision': 0.18181818181818182, 'recall': 0.6666666666666666, 'f1-score': 0.28571428571428575, 'support': 3.0}\n",
      "========================================\n",
      "Class Class_1 Classification Report:\n",
      "metric: Class_1, class_label: Class_1\n",
      "1: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 5.0}\n",
      "========================================\n",
      "Class Class_2 Classification Report:\n",
      "metric: Class_2, class_label: Class_2\n",
      "2: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 3.0}\n",
      "========================================\n",
      "Class Class_3 Classification Report:\n",
      "metric: Class_3, class_label: Class_3\n",
      "3: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 3.0}\n",
      "========================================\n",
      "Class Class_4 Classification Report:\n",
      "metric: Class_4, class_label: Class_4\n",
      "4: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 5.0}\n",
      "========================================\n",
      "Class Class_5 Classification Report:\n",
      "metric: Class_5, class_label: Class_5\n",
      "5: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 5.0}\n",
      "========================================\n",
      "########################################\n",
      "########################################\n",
      "\n",
      "Augmentation:  == UnnamedFlipud ==\n",
      "\n",
      "========================================\n",
      "Class Class_0 Classification Report:\n",
      "metric: Class_0, class_label: Class_0\n",
      "0: {'precision': 0.18181818181818182, 'recall': 0.6666666666666666, 'f1-score': 0.28571428571428575, 'support': 3.0}\n",
      "========================================\n",
      "Class Class_1 Classification Report:\n",
      "metric: Class_1, class_label: Class_1\n",
      "1: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 5.0}\n",
      "========================================\n",
      "Class Class_2 Classification Report:\n",
      "metric: Class_2, class_label: Class_2\n",
      "2: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 3.0}\n",
      "========================================\n",
      "Class Class_3 Classification Report:\n",
      "metric: Class_3, class_label: Class_3\n",
      "3: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 3.0}\n",
      "========================================\n",
      "Class Class_4 Classification Report:\n",
      "metric: Class_4, class_label: Class_4\n",
      "4: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 5.0}\n",
      "========================================\n",
      "Class Class_5 Classification Report:\n",
      "metric: Class_5, class_label: Class_5\n",
      "5: {'precision': 0.2727272727272727, 'recall': 0.6, 'f1-score': 0.37499999999999994, 'support': 5.0}\n",
      "========================================\n",
      "########################################\n",
      "########################################\n",
      "\n",
      "Augmentation:  == UnnamedMultiply ==\n",
      "\n",
      "========================================\n",
      "Class Class_0 Classification Report:\n",
      "metric: Class_0, class_label: Class_0\n",
      "0: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 3.0}\n",
      "========================================\n",
      "Class Class_1 Classification Report:\n",
      "metric: Class_1, class_label: Class_1\n",
      "1: {'precision': 1.0, 'recall': 0.2, 'f1-score': 0.33333333333333337, 'support': 5.0}\n",
      "========================================\n",
      "Class Class_2 Classification Report:\n",
      "metric: Class_2, class_label: Class_2\n",
      "2: {'precision': 0.18181818181818182, 'recall': 0.6666666666666666, 'f1-score': 0.28571428571428575, 'support': 3.0}\n",
      "========================================\n",
      "Class Class_3 Classification Report:\n",
      "metric: Class_3, class_label: Class_3\n",
      "3: {'precision': 0.2727272727272727, 'recall': 1.0, 'f1-score': 0.42857142857142855, 'support': 3.0}\n",
      "========================================\n",
      "Class Class_4 Classification Report:\n",
      "metric: Class_4, class_label: Class_4\n",
      "4: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 5.0}\n",
      "========================================\n",
      "Class Class_5 Classification Report:\n",
      "metric: Class_5, class_label: Class_5\n",
      "5: {'precision': 0.25, 'recall': 0.2, 'f1-score': 0.22222222222222224, 'support': 5.0}\n",
      "========================================\n",
      "########################################\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from imgaug import augmenters as iaa\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import warnings\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load the dataset from the CSV file\n",
    "data = pd.read_csv(\"../csv/minority_train.csv\")\n",
    "\n",
    "# Initialize variables to store sampled data as lists\n",
    "sampled_image_paths = []\n",
    "sampled_class_labels = []\n",
    "\n",
    "# Specify the number of samples per class and the total number of samples\n",
    "samples_per_class = 20  # Adjust as needed\n",
    "total_samples = 100\n",
    "\n",
    "# Iterate through unique classes\n",
    "unique_classes = data[\"dx\"].unique()\n",
    "for class_label in unique_classes:\n",
    "    # Select samples for the current class\n",
    "    class_data = data[data[\"dx\"] == class_label].head(samples_per_class)\n",
    "    \n",
    "    # Append the sampled image paths and class labels to the result lists\n",
    "    sampled_image_paths.extend(class_data[\"image_pth\"].tolist())\n",
    "    sampled_class_labels.extend(class_data[\"dx\"].tolist())\n",
    "\n",
    "\n",
    "# Initialize an empty list to store images\n",
    "images = []\n",
    "\n",
    "# Load images using OpenCV and convert to grayscale\n",
    "for image_path in sampled_image_paths:\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    images.append(image)\n",
    "\n",
    "\n",
    "X = np.array(images)  # Convert to numpy array\n",
    "\n",
    "# Convert class labels to numeric values\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(sampled_class_labels)\n",
    "\n",
    "# Flatten the image data\n",
    "X = X.reshape(X.shape[0], -1)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "print(f\"ytest: {np.unique(y_test)}\")\n",
    "print(f\"ytrain: {np.unique(y_train)}\")\n",
    "\n",
    "class_distribution_test = np.bincount(y_test)\n",
    "class_distribution_train = np.bincount(y_train)\n",
    "print(\"Class distribution in y_test:\", class_distribution_test)\n",
    "print(\"Class distribution in y_train:\", class_distribution_train)\n",
    "\n",
    "# Generate a synthetic multiclass classification dataset (you should replace this with your real data)\n",
    "# X, y = make_classification(n_samples=1000, n_features=20, n_classes=5, n_informative=5, random_state=42)\n",
    "\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = (X_train * 255).astype(np.uint8)\n",
    "X_test = (X_test * 255).astype(np.uint8)\n",
    "\n",
    "# Define a list of augmentation techniques\n",
    "augmentations = [\n",
    "    iaa.Fliplr(0.5),  # Horizontal flip with 50% probability\n",
    "    iaa.Flipud(0.5),  # Vertical flip with 50% probability\n",
    "    # iaa.Affine(rotate=(-45, 45)),  # Rotation between -45 and 45 degrees\n",
    "    iaa.Multiply((0.5, 1.5)),  # Brightness multiplication between 0.5 and 1.5\n",
    "]\n",
    "\n",
    "# Define the base classifier (Decision Tree)\n",
    "base_classifier = DecisionTreeClassifier(max_depth=1)\n",
    "\n",
    "# Initialize AdaBoostClassifier with the base classifier\n",
    "\n",
    "adaboost_classifier = AdaBoostClassifier(base_classifier, n_estimators=50, random_state=42)\n",
    "\n",
    "# Create a dictionary to store classification reports for each augmentation and class\n",
    "augmentation_reports = {}\n",
    "unique_classes_test = np.unique(y_test)\n",
    "\n",
    "\n",
    "# Train AdaBoost with each augmentation technique for each class and record classification report\n",
    "num_iterations = 10  # Number of iterations to test each augmentation\n",
    "consolidated_x = []\n",
    "consolidated_y = []\n",
    "for augmentation in augmentations:\n",
    "    augmentation_reports[augmentation] = {}\n",
    "    print(f\"Augmentation: {augmentation.name}\")\n",
    "    for class_label in np.unique(y_train):\n",
    "        print(f\"Class: {class_label}\")\n",
    "        class_mask = (y_train == class_label)\n",
    "        other_mask = (y_train != class_label)\n",
    "        \n",
    "        other_labels = []\n",
    "        class_labels = []\n",
    "        \n",
    "        for label in other_mask:\n",
    "            other_labels.append(label)\n",
    "        \n",
    "        for label in class_mask:\n",
    "            class_labels.append(label)\n",
    "        \n",
    "        augmented_X_train = X_train[class_mask].copy()\n",
    "        non_augmented_X_train = X_train[other_mask].copy()\n",
    "        \n",
    "        # Apply augmentation to the samples of the current class\n",
    "        augmented_X_train = augmentation.augment_images(augmented_X_train)\n",
    "        \n",
    "        \n",
    "        # augmented should be combined with X-train left over data.\n",
    "        all_data = np.concatenate((augmented_X_train, non_augmented_X_train), axis=0)\n",
    "        all_labels = np.concatenate((y_train[class_mask], y_train[other_mask]), axis=0)\n",
    "        \n",
    "        # Fit AdaBoost classifier for the current class\n",
    "        # adaboost_classifier.fit(augmented_X_train, y_train[class_mask])\n",
    "        adaboost_classifier.fit(all_data, all_labels)\n",
    "        \n",
    "        \n",
    "        # Evaluate the classifier on the test set\n",
    "        y_pred = adaboost_classifier.predict(X_test)\n",
    "        # Check unique classes in y_test and y_pred\n",
    "        print(f'Unique classes test : {np.unique(y_test)}')\n",
    "        print(f'Unique classes pred : {np.unique(y_pred)}')\n",
    "        \n",
    "        # # Confirm that both sets of unique classes match\n",
    "        # if np.array_equal(unique_classes_test, unique_classes_pred):\n",
    "        #     target_names = [f'Class_{i}' for i in unique_classes_test]\n",
    "        # else:\n",
    "        #     print(\"Mismatch in unique classes between y_test and y_pred.\")\n",
    "        \n",
    "        # Then, when calling classification_report, pass the target_names parameter\n",
    "        classification_rep = classification_report(y_test, y_pred, target_names=unique_classes_test, output_dict=True)\n",
    "        # Store the classification report in the dictionary with keys based on augmentation and class\n",
    "        augmentation_reports[augmentation][f'Class_{class_label}'] = classification_rep\n",
    "\n",
    "# Print the classification report for each augmentation technique and class\n",
    "for augmentation, class_reports in augmentation_reports.items():\n",
    "    print(\"#\" * 40)\n",
    "    print(f\"\\nAugmentation:  == {augmentation.name} ==\\n\")\n",
    "    print(\"=\" * 40)\n",
    "    for class_label, report in class_reports.items():\n",
    "        print(f\"Class {class_label} Classification Report:\")\n",
    "        for metric, value in report.items():\n",
    "            if metric != 'accuracy' and f\"Class_{metric}\" == class_label:\n",
    "                print(f\"metric: Class_{metric}, class_label: {class_label}\")\n",
    "                print(f\"{metric}: {value:.2f}\" if isinstance(value, (float, np.float32)) else f\"{metric}: {value}\")\n",
    "        print(\"=\" * 40)\n",
    "    print(\"#\" * 40)\n",
    "\n",
    "\n",
    "with open('./augment/metrics.txt', 'w+')as metrics:\n",
    "    json.dump(augmentation_reports, metrics)\n",
    "# print(\"*\" * 40)\n",
    "# print(class_reports)\n",
    "# print(\"*\" * 40)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[3 2 2 3 1 3 4 5 4 3 1 3 5 2 5 5 2 5 2 4 2 1 3 3 1 3 4 2 1 1 1 3 5 1 4 4 5\n",
      " 2 4 3 4 3 1 1 4 1 1 3 3 3 2 2 5 5 2 1 4 5 1 2 3 4 1 4 5 4 2 5 1 1 2 5 1 1\n",
      " 1 4 4 1 3 3 4 5 2 2 4 3 4 5 3 1 5 2 5 3 5 1 2 2 2 5 4 5 5]\n"
     ]
    }
   ],
   "source": [
    "y_test_transformed = y_test\n",
    "y_train_transformed = y_train\n",
    "label = 0\n",
    "\n",
    "selected_ytest = (y_test_transformed == label)\n",
    "selected_ytrain = (y_train_transformed == label)\n",
    "\n",
    "notSelected_ytest = (y_test_transformed != label)\n",
    "notSelected_ytrain = (y_train_transformed != label)\n",
    "\n",
    "\n",
    "print(y_test[selected_ytest])\n",
    "print(y_test[notSelected_ytest])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "# Change the labels to 0 for augmented class and 1 for other class\n",
    "labels = []\n",
    "for item in notSelected_ytrain:\n",
    "    if item == 1:\n",
    "        labels.append(1)        \n",
    "    else:\n",
    "        item = 0\n",
    "        labels.append(item)\n",
    "\n",
    "print(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ytest: [0 1 2 3 4 5]\n",
      "ytrain: [0 1 2 3 4 5]\n",
      "Class distribution in y_test: [3 5 3 3 5 5]\n",
      "Class distribution in y_train: [17 15 17 17 15 15]\n",
      "Class: 0\n",
      " === Augmentation: UnnamedFliplr === \n",
      "Unique classes test : [0 1 2 3 4 5]\n",
      "Unique classes pred : [0 2 5]\n",
      " === Augmentation: UnnamedFlipud === \n",
      "Unique classes test : [0 1 2 3 4 5]\n",
      "Unique classes pred : [0 1 5]\n",
      " === Augmentation: UnnamedMultiply === \n",
      "Unique classes test : [0 1 2 3 4 5]\n",
      "Unique classes pred : [0 2 3]\n",
      "Class: 1\n",
      " === Augmentation: UnnamedFliplr === \n",
      "Unique classes test : [0 1 2 3 4 5]\n",
      "Unique classes pred : [0 5]\n",
      " === Augmentation: UnnamedFlipud === \n",
      "Unique classes test : [0 1 2 3 4 5]\n",
      "Unique classes pred : [0 1 5]\n",
      " === Augmentation: UnnamedMultiply === \n",
      "Unique classes test : [0 1 2 3 4 5]\n",
      "Unique classes pred : [1 2 3 4 5]\n",
      "Class: 2\n",
      " === Augmentation: UnnamedFliplr === \n",
      "Unique classes test : [0 1 2 3 4 5]\n",
      "Unique classes pred : [0 1 5]\n",
      " === Augmentation: UnnamedFlipud === \n",
      "Unique classes test : [0 1 2 3 4 5]\n",
      "Unique classes pred : [0 1 5]\n",
      " === Augmentation: UnnamedMultiply === \n",
      "Unique classes test : [0 1 2 3 4 5]\n",
      "Unique classes pred : [0 2 3]\n",
      "Class: 3\n",
      " === Augmentation: UnnamedFliplr === \n",
      "Unique classes test : [0 1 2 3 4 5]\n",
      "Unique classes pred : [0 1 2 3 4 5]\n",
      " === Augmentation: UnnamedFlipud === \n",
      "Unique classes test : [0 1 2 3 4 5]\n",
      "Unique classes pred : [0 1 5]\n",
      " === Augmentation: UnnamedMultiply === \n",
      "Unique classes test : [0 1 2 3 4 5]\n",
      "Unique classes pred : [0 3 5]\n",
      "Class: 4\n",
      " === Augmentation: UnnamedFliplr === \n",
      "Unique classes test : [0 1 2 3 4 5]\n",
      "Unique classes pred : [0 1 5]\n",
      " === Augmentation: UnnamedFlipud === \n",
      "Unique classes test : [0 1 2 3 4 5]\n",
      "Unique classes pred : [0 1 5]\n",
      " === Augmentation: UnnamedMultiply === \n",
      "Unique classes test : [0 1 2 3 4 5]\n",
      "Unique classes pred : [0]\n",
      "Class: 5\n",
      " === Augmentation: UnnamedFliplr === \n",
      "Unique classes test : [0 1 2 3 4 5]\n",
      "Unique classes pred : [0 1 5]\n",
      " === Augmentation: UnnamedFlipud === \n",
      "Unique classes test : [0 1 2 3 4 5]\n",
      "Unique classes pred : [0 1 5]\n",
      " === Augmentation: UnnamedMultiply === \n",
      "Unique classes test : [0 1 2 3 4 5]\n",
      "Unique classes pred : [0 1 2 5]\n",
      "########################################\n",
      "\n",
      "Augmentation:  == UnnamedFliplr ==\n",
      "\n",
      "========================================\n",
      "Class Class_5 Classification Report:\n",
      "metric: Class_5, class_label: Class_5\n",
      "5: {'precision': 0.2727272727272727, 'recall': 0.6, 'f1-score': 0.37499999999999994, 'support': 5.0}\n",
      "========================================\n",
      "########################################\n",
      "########################################\n",
      "\n",
      "Augmentation:  == UnnamedFlipud ==\n",
      "\n",
      "========================================\n",
      "Class Class_5 Classification Report:\n",
      "metric: Class_5, class_label: Class_5\n",
      "5: {'precision': 0.2727272727272727, 'recall': 0.6, 'f1-score': 0.37499999999999994, 'support': 5.0}\n",
      "========================================\n",
      "########################################\n",
      "########################################\n",
      "\n",
      "Augmentation:  == UnnamedMultiply ==\n",
      "\n",
      "========================================\n",
      "Class Class_5 Classification Report:\n",
      "metric: Class_5, class_label: Class_5\n",
      "5: {'precision': 0.4, 'recall': 0.4, 'f1-score': 0.4000000000000001, 'support': 5.0}\n",
      "========================================\n",
      "########################################\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './augment/metrics.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/admin/Documents/Github/SkinCancer/augment/misc.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/admin/Documents/Github/SkinCancer/augment/misc.ipynb#X11sZmlsZQ%3D%3D?line=149'>150</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m*\u001b[39m \u001b[39m40\u001b[39m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/admin/Documents/Github/SkinCancer/augment/misc.ipynb#X11sZmlsZQ%3D%3D?line=150'>151</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m#\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m*\u001b[39m \u001b[39m40\u001b[39m)\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/admin/Documents/Github/SkinCancer/augment/misc.ipynb#X11sZmlsZQ%3D%3D?line=153'>154</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(\u001b[39m'\u001b[39;49m\u001b[39m./augment/metrics.txt\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mw+\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39mas\u001b[39;00m metrics:\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/admin/Documents/Github/SkinCancer/augment/misc.ipynb#X11sZmlsZQ%3D%3D?line=154'>155</a>\u001b[0m     json\u001b[39m.\u001b[39mdump(augmentation_reports, metrics)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/admin/Documents/Github/SkinCancer/augment/misc.ipynb#X11sZmlsZQ%3D%3D?line=155'>156</a>\u001b[0m \u001b[39m# print(\"*\" * 40)\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/admin/Documents/Github/SkinCancer/augment/misc.ipynb#X11sZmlsZQ%3D%3D?line=156'>157</a>\u001b[0m \u001b[39m# print(class_reports)\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/admin/Documents/Github/SkinCancer/augment/misc.ipynb#X11sZmlsZQ%3D%3D?line=157'>158</a>\u001b[0m \u001b[39m# print(\"*\" * 40)\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Github/SkinCancer/env/lib/python3.9/site-packages/IPython/core/interactiveshell.py:286\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[1;32m    280\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    281\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    283\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    284\u001b[0m     )\n\u001b[0;32m--> 286\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './augment/metrics.txt'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from imgaug import augmenters as iaa\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import warnings\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load the dataset from the CSV file\n",
    "data = pd.read_csv(\"../csv/minority_train.csv\")\n",
    "\n",
    "# Initialize variables to store sampled data as lists\n",
    "sampled_image_paths = []\n",
    "sampled_class_labels = []\n",
    "\n",
    "# Specify the number of samples per class and the total number of samples\n",
    "samples_per_class = 20  # Adjust as needed\n",
    "total_samples = 100\n",
    "\n",
    "# Iterate through unique classes\n",
    "unique_classes = data[\"dx\"].unique()\n",
    "for class_label in unique_classes:\n",
    "    # Select samples for the current class\n",
    "    class_data = data[data[\"dx\"] == class_label].head(samples_per_class)\n",
    "    \n",
    "    # Append the sampled image paths and class labels to the result lists\n",
    "    sampled_image_paths.extend(class_data[\"image_pth\"].tolist())\n",
    "    sampled_class_labels.extend(class_data[\"dx\"].tolist())\n",
    "\n",
    "\n",
    "# Initialize an empty list to store images\n",
    "images = []\n",
    "\n",
    "# Load images using OpenCV and convert to grayscale\n",
    "for image_path in sampled_image_paths:\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    images.append(image)\n",
    "\n",
    "\n",
    "X = np.array(images)  # Convert to numpy array\n",
    "\n",
    "# Convert class labels to numeric values\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(sampled_class_labels)\n",
    "\n",
    "# Flatten the image data\n",
    "X = X.reshape(X.shape[0], -1)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "print(f\"ytest: {np.unique(y_test)}\")\n",
    "print(f\"ytrain: {np.unique(y_train)}\")\n",
    "\n",
    "class_distribution_test = np.bincount(y_test)\n",
    "class_distribution_train = np.bincount(y_train)\n",
    "print(\"Class distribution in y_test:\", class_distribution_test)\n",
    "print(\"Class distribution in y_train:\", class_distribution_train)\n",
    "\n",
    "# Generate a synthetic multiclass classification dataset (you should replace this with your real data)\n",
    "# X, y = make_classification(n_samples=1000, n_features=20, n_classes=5, n_informative=5, random_state=42)\n",
    "\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = (X_train * 255).astype(np.uint8)\n",
    "X_test = (X_test * 255).astype(np.uint8)\n",
    "\n",
    "# Define a list of augmentation techniques\n",
    "augmentations = [\n",
    "    iaa.Fliplr(0.5),  # Horizontal flip with 50% probability\n",
    "    iaa.Flipud(0.5),  # Vertical flip with 50% probability\n",
    "    # iaa.Affine(rotate=(-45, 45)),  # Rotation between -45 and 45 degrees\n",
    "    iaa.Multiply((0.5, 1.5)),  # Brightness multiplication between 0.5 and 1.5\n",
    "]\n",
    "\n",
    "# Define the base classifier (Decision Tree)\n",
    "base_classifier = DecisionTreeClassifier(max_depth=1)\n",
    "\n",
    "# Initialize AdaBoostClassifier with the base classifier\n",
    "\n",
    "adaboost_classifier = AdaBoostClassifier(base_classifier, n_estimators=50, random_state=42)\n",
    "\n",
    "# Create a dictionary to store classification reports for each augmentation and class\n",
    "augmentation_reports = {}\n",
    "unique_classes_test = np.unique(y_test)\n",
    "\n",
    "\n",
    "# Train AdaBoost with each augmentation technique for each class and record classification report\n",
    "num_iterations = 10  # Number of iterations to test each augmentation\n",
    "consolidated_x = []\n",
    "consolidated_y = []\n",
    "\n",
    "for class_label in np.unique(y_train):\n",
    "    print(f\"Class: {class_label}\")\n",
    "    class_mask = (y_train == class_label)\n",
    "    other_mask = (y_train != class_label)\n",
    "    for augmentation in augmentations:\n",
    "        print(f' === Augmentation: {augmentation.name} === ')\n",
    "        augmentation_reports[augmentation] = {}    \n",
    "        augmented_X_train = X_train[class_mask].copy()\n",
    "        non_augmented_X_train = X_train[other_mask].copy()\n",
    "    \n",
    "        # Apply augmentation to the samples of the current class\n",
    "        augmented_X_train = augmentation.augment_images(augmented_X_train)\n",
    "    \n",
    "        # augmented should be combined with X-train left over data.\n",
    "        all_data = np.concatenate((augmented_X_train, non_augmented_X_train), axis=0)\n",
    "        all_labels = np.concatenate((y_train[class_mask], y_train[other_mask]), axis=0)\n",
    "    \n",
    "        # Fit AdaBoost classifier for the current class\n",
    "        # adaboost_classifier.fit(augmented_X_train, y_train[class_mask])\n",
    "        adaboost_classifier.fit(all_data, all_labels)\n",
    "    \n",
    "    \n",
    "        # Evaluate the classifier on the test set\n",
    "        y_pred = adaboost_classifier.predict(X_test)\n",
    "        # Check unique classes in y_test and y_pred\n",
    "        print(f'Unique classes test : {y_test}')\n",
    "        print(f'Unique classes pred : {y_pred}')\n",
    "        \n",
    "        for idx in range(0, len(X_test)):\n",
    "            plt.plot(X_test[idx].reshape(450, 600), cmap='gray')\n",
    "            plt.savefig(f'./augment/images/{y_pred},{y_test}.png')\n",
    "        # Then, when calling classification_report, pass the target_names parameter\n",
    "        classification_rep = classification_report(y_test, y_pred, target_names=unique_classes_test, output_dict=True)\n",
    "        # Store the classification report in the dictionary with keys based on augmentation and class\n",
    "        augmentation_reports[augmentation][f'Class_{class_label}'] = classification_rep\n",
    "\n",
    "# Print the classification report for each augmentation technique and class\n",
    "for augmentation, class_reports in augmentation_reports.items():\n",
    "    print(\"#\" * 40)\n",
    "    print(f\"\\nAugmentation:  == {augmentation.name} ==\\n\")\n",
    "    print(\"=\" * 40)\n",
    "    for class_label, report in class_reports.items():\n",
    "        print(f\"Class {class_label} Classification Report:\")\n",
    "        for metric, value in report.items():\n",
    "            if metric != 'accuracy' and f\"Class_{metric}\" == class_label:\n",
    "                print(f\"metric: Class_{metric}, class_label: {class_label}\")\n",
    "                print(f\"{metric}: {value:.2f}\" if isinstance(value, (float, np.float32)) else f\"{metric}: {value}\")\n",
    "        print(\"=\" * 40)\n",
    "    print(\"#\" * 40)\n",
    "\n",
    "\n",
    "with open('metrics.txt', 'w+')as metrics:\n",
    "   metrics.write(str(augmentation_reports))\n",
    "# print(\"*\" * 40)\n",
    "# print(class_reports)\n",
    "# print(\"*\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
