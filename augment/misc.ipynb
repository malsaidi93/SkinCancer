{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ytest: [0 1 2 3 4 5]\n",
      "ytrain: [0 1 2 3 4 5]\n",
      "Class distribution in y_test: [3 5 3 3 5 5]\n",
      "Class distribution in y_train: [17 15 17 17 15 15]\n",
      "Augmentation: UnnamedFliplr\n",
      "Class: 0\n",
      "Unique classes test : [0 1 2 3 4 5]\n",
      "Unique classes pred : [0 1 5]\n",
      "Class: 1\n",
      "Unique classes test : [0 1 2 3 4 5]\n",
      "Unique classes pred : [0 5]\n",
      "Class: 2\n",
      "Unique classes test : [0 1 2 3 4 5]\n",
      "Unique classes pred : [0 1 5]\n",
      "Class: 3\n",
      "Unique classes test : [0 1 2 3 4 5]\n",
      "Unique classes pred : [0 1 5]\n",
      "Class: 4\n",
      "Unique classes test : [0 1 2 3 4 5]\n",
      "Unique classes pred : [0 2 5]\n",
      "Class: 5\n",
      "Unique classes test : [0 1 2 3 4 5]\n",
      "Unique classes pred : [0 1 2]\n",
      "Augmentation: UnnamedFlipud\n",
      "Class: 0\n",
      "Unique classes test : [0 1 2 3 4 5]\n",
      "Unique classes pred : [0 1 5]\n",
      "Class: 1\n",
      "Unique classes test : [0 1 2 3 4 5]\n",
      "Unique classes pred : [0 1 5]\n",
      "Class: 2\n",
      "Unique classes test : [0 1 2 3 4 5]\n",
      "Unique classes pred : [0 1 5]\n",
      "Class: 3\n",
      "Unique classes test : [0 1 2 3 4 5]\n",
      "Unique classes pred : [0 1 5]\n",
      "Class: 4\n",
      "Unique classes test : [0 1 2 3 4 5]\n",
      "Unique classes pred : [0 1 5]\n",
      "Class: 5\n",
      "Unique classes test : [0 1 2 3 4 5]\n",
      "Unique classes pred : [0 1 5]\n",
      "Augmentation: UnnamedMultiply\n",
      "Class: 0\n",
      "Unique classes test : [0 1 2 3 4 5]\n",
      "Unique classes pred : [0 2 3 4]\n",
      "Class: 1\n",
      "Unique classes test : [0 1 2 3 4 5]\n",
      "Unique classes pred : [0 1 5]\n",
      "Class: 2\n",
      "Unique classes test : [0 1 2 3 4 5]\n",
      "Unique classes pred : [0 1 2 4 5]\n",
      "Class: 3\n",
      "Unique classes test : [0 1 2 3 4 5]\n",
      "Unique classes pred : [0 1 2 3 5]\n",
      "Class: 4\n",
      "Unique classes test : [0 1 2 3 4 5]\n",
      "Unique classes pred : [0 1 2 3 4 5]\n",
      "Class: 5\n",
      "Unique classes test : [0 1 2 3 4 5]\n",
      "Unique classes pred : [1 2 3 4 5]\n",
      "########################################\n",
      "\n",
      "Augmentation:  == UnnamedFliplr ==\n",
      "\n",
      "========================================\n",
      "Class Class_0 Classification Report:\n",
      "metric: Class_0, class_label: Class_0\n",
      "0: {'precision': 0.18181818181818182, 'recall': 0.6666666666666666, 'f1-score': 0.28571428571428575, 'support': 3.0}\n",
      "========================================\n",
      "Class Class_1 Classification Report:\n",
      "metric: Class_1, class_label: Class_1\n",
      "1: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 5.0}\n",
      "========================================\n",
      "Class Class_2 Classification Report:\n",
      "metric: Class_2, class_label: Class_2\n",
      "2: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 3.0}\n",
      "========================================\n",
      "Class Class_3 Classification Report:\n",
      "metric: Class_3, class_label: Class_3\n",
      "3: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 3.0}\n",
      "========================================\n",
      "Class Class_4 Classification Report:\n",
      "metric: Class_4, class_label: Class_4\n",
      "4: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 5.0}\n",
      "========================================\n",
      "Class Class_5 Classification Report:\n",
      "metric: Class_5, class_label: Class_5\n",
      "5: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 5.0}\n",
      "========================================\n",
      "########################################\n",
      "########################################\n",
      "\n",
      "Augmentation:  == UnnamedFlipud ==\n",
      "\n",
      "========================================\n",
      "Class Class_0 Classification Report:\n",
      "metric: Class_0, class_label: Class_0\n",
      "0: {'precision': 0.18181818181818182, 'recall': 0.6666666666666666, 'f1-score': 0.28571428571428575, 'support': 3.0}\n",
      "========================================\n",
      "Class Class_1 Classification Report:\n",
      "metric: Class_1, class_label: Class_1\n",
      "1: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 5.0}\n",
      "========================================\n",
      "Class Class_2 Classification Report:\n",
      "metric: Class_2, class_label: Class_2\n",
      "2: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 3.0}\n",
      "========================================\n",
      "Class Class_3 Classification Report:\n",
      "metric: Class_3, class_label: Class_3\n",
      "3: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 3.0}\n",
      "========================================\n",
      "Class Class_4 Classification Report:\n",
      "metric: Class_4, class_label: Class_4\n",
      "4: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 5.0}\n",
      "========================================\n",
      "Class Class_5 Classification Report:\n",
      "metric: Class_5, class_label: Class_5\n",
      "5: {'precision': 0.2727272727272727, 'recall': 0.6, 'f1-score': 0.37499999999999994, 'support': 5.0}\n",
      "========================================\n",
      "########################################\n",
      "########################################\n",
      "\n",
      "Augmentation:  == UnnamedMultiply ==\n",
      "\n",
      "========================================\n",
      "Class Class_0 Classification Report:\n",
      "metric: Class_0, class_label: Class_0\n",
      "0: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 3.0}\n",
      "========================================\n",
      "Class Class_1 Classification Report:\n",
      "metric: Class_1, class_label: Class_1\n",
      "1: {'precision': 1.0, 'recall': 0.2, 'f1-score': 0.33333333333333337, 'support': 5.0}\n",
      "========================================\n",
      "Class Class_2 Classification Report:\n",
      "metric: Class_2, class_label: Class_2\n",
      "2: {'precision': 0.18181818181818182, 'recall': 0.6666666666666666, 'f1-score': 0.28571428571428575, 'support': 3.0}\n",
      "========================================\n",
      "Class Class_3 Classification Report:\n",
      "metric: Class_3, class_label: Class_3\n",
      "3: {'precision': 0.2727272727272727, 'recall': 1.0, 'f1-score': 0.42857142857142855, 'support': 3.0}\n",
      "========================================\n",
      "Class Class_4 Classification Report:\n",
      "metric: Class_4, class_label: Class_4\n",
      "4: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 5.0}\n",
      "========================================\n",
      "Class Class_5 Classification Report:\n",
      "metric: Class_5, class_label: Class_5\n",
      "5: {'precision': 0.25, 'recall': 0.2, 'f1-score': 0.22222222222222224, 'support': 5.0}\n",
      "========================================\n",
      "########################################\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from imgaug import augmenters as iaa\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import warnings\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load the dataset from the CSV file\n",
    "data = pd.read_csv(\"../csv/minority_train.csv\")\n",
    "\n",
    "# Initialize variables to store sampled data as lists\n",
    "sampled_image_paths = []\n",
    "sampled_class_labels = []\n",
    "\n",
    "# Specify the number of samples per class and the total number of samples\n",
    "samples_per_class = 20  # Adjust as needed\n",
    "total_samples = 100\n",
    "\n",
    "# Iterate through unique classes\n",
    "unique_classes = data[\"dx\"].unique()\n",
    "for class_label in unique_classes:\n",
    "    # Select samples for the current class\n",
    "    class_data = data[data[\"dx\"] == class_label].head(samples_per_class)\n",
    "    \n",
    "    # Append the sampled image paths and class labels to the result lists\n",
    "    sampled_image_paths.extend(class_data[\"image_pth\"].tolist())\n",
    "    sampled_class_labels.extend(class_data[\"dx\"].tolist())\n",
    "\n",
    "\n",
    "# Initialize an empty list to store images\n",
    "images = []\n",
    "\n",
    "# Load images using OpenCV and convert to grayscale\n",
    "for image_path in sampled_image_paths:\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    images.append(image)\n",
    "\n",
    "\n",
    "X = np.array(images)  # Convert to numpy array\n",
    "\n",
    "# Convert class labels to numeric values\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(sampled_class_labels)\n",
    "\n",
    "# Flatten the image data\n",
    "X = X.reshape(X.shape[0], -1)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "print(f\"ytest: {np.unique(y_test)}\")\n",
    "print(f\"ytrain: {np.unique(y_train)}\")\n",
    "\n",
    "class_distribution_test = np.bincount(y_test)\n",
    "class_distribution_train = np.bincount(y_train)\n",
    "print(\"Class distribution in y_test:\", class_distribution_test)\n",
    "print(\"Class distribution in y_train:\", class_distribution_train)\n",
    "\n",
    "# Generate a synthetic multiclass classification dataset (you should replace this with your real data)\n",
    "# X, y = make_classification(n_samples=1000, n_features=20, n_classes=5, n_informative=5, random_state=42)\n",
    "\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = (X_train * 255).astype(np.uint8)\n",
    "X_test = (X_test * 255).astype(np.uint8)\n",
    "\n",
    "# Define a list of augmentation techniques\n",
    "augmentations = [\n",
    "    iaa.Fliplr(0.5),  # Horizontal flip with 50% probability\n",
    "    iaa.Flipud(0.5),  # Vertical flip with 50% probability\n",
    "    # iaa.Affine(rotate=(-45, 45)),  # Rotation between -45 and 45 degrees\n",
    "    iaa.Multiply((0.5, 1.5)),  # Brightness multiplication between 0.5 and 1.5\n",
    "]\n",
    "\n",
    "# Define the base classifier (Decision Tree)\n",
    "base_classifier = DecisionTreeClassifier(max_depth=1)\n",
    "\n",
    "# Initialize AdaBoostClassifier with the base classifier\n",
    "\n",
    "adaboost_classifier = AdaBoostClassifier(base_classifier, n_estimators=50, random_state=42)\n",
    "\n",
    "# Create a dictionary to store classification reports for each augmentation and class\n",
    "augmentation_reports = {}\n",
    "unique_classes_test = np.unique(y_test)\n",
    "\n",
    "\n",
    "# Train AdaBoost with each augmentation technique for each class and record classification report\n",
    "num_iterations = 10  # Number of iterations to test each augmentation\n",
    "consolidated_x = []\n",
    "consolidated_y = []\n",
    "for augmentation in augmentations:\n",
    "    augmentation_reports[augmentation] = {}\n",
    "    print(f\"Augmentation: {augmentation.name}\")\n",
    "    for class_label in np.unique(y_train):\n",
    "        print(f\"Class: {class_label}\")\n",
    "        class_mask = (y_train == class_label)\n",
    "        other_mask = (y_train != class_label)\n",
    "        \n",
    "        other_labels = []\n",
    "        class_labels = []\n",
    "        \n",
    "        for label in other_mask:\n",
    "            other_labels.append(label)\n",
    "        \n",
    "        for label in class_mask:\n",
    "            class_labels.append(label)\n",
    "        \n",
    "        augmented_X_train = X_train[class_mask].copy()\n",
    "        non_augmented_X_train = X_train[other_mask].copy()\n",
    "        \n",
    "        # Apply augmentation to the samples of the current class\n",
    "        augmented_X_train = augmentation.augment_images(augmented_X_train)\n",
    "        \n",
    "        \n",
    "        # augmented should be combined with X-train left over data.\n",
    "        all_data = np.concatenate((augmented_X_train, non_augmented_X_train), axis=0)\n",
    "        all_labels = np.concatenate((y_train[class_mask], y_train[other_mask]), axis=0)\n",
    "        \n",
    "        # Fit AdaBoost classifier for the current class\n",
    "        # adaboost_classifier.fit(augmented_X_train, y_train[class_mask])\n",
    "        adaboost_classifier.fit(all_data, all_labels)\n",
    "        \n",
    "        \n",
    "        # Evaluate the classifier on the test set\n",
    "        y_pred = adaboost_classifier.predict(X_test)\n",
    "        # Check unique classes in y_test and y_pred\n",
    "        print(f'Unique classes test : {np.unique(y_test)}')\n",
    "        print(f'Unique classes pred : {np.unique(y_pred)}')\n",
    "        \n",
    "        # # Confirm that both sets of unique classes match\n",
    "        # if np.array_equal(unique_classes_test, unique_classes_pred):\n",
    "        #     target_names = [f'Class_{i}' for i in unique_classes_test]\n",
    "        # else:\n",
    "        #     print(\"Mismatch in unique classes between y_test and y_pred.\")\n",
    "        \n",
    "        # Then, when calling classification_report, pass the target_names parameter\n",
    "        classification_rep = classification_report(y_test, y_pred, target_names=unique_classes_test, output_dict=True)\n",
    "        # Store the classification report in the dictionary with keys based on augmentation and class\n",
    "        augmentation_reports[augmentation][f'Class_{class_label}'] = classification_rep\n",
    "\n",
    "# Print the classification report for each augmentation technique and class\n",
    "for augmentation, class_reports in augmentation_reports.items():\n",
    "    print(\"#\" * 40)\n",
    "    print(f\"\\nAugmentation:  == {augmentation.name} ==\\n\")\n",
    "    print(\"=\" * 40)\n",
    "    for class_label, report in class_reports.items():\n",
    "        print(f\"Class {class_label} Classification Report:\")\n",
    "        for metric, value in report.items():\n",
    "            if metric != 'accuracy' and f\"Class_{metric}\" == class_label:\n",
    "                print(f\"metric: Class_{metric}, class_label: {class_label}\")\n",
    "                print(f\"{metric}: {value:.2f}\" if isinstance(value, (float, np.float32)) else f\"{metric}: {value}\")\n",
    "        print(\"=\" * 40)\n",
    "    print(\"#\" * 40)\n",
    "\n",
    "\n",
    "with open('./augment/metrics.txt', 'w+')as metrics:\n",
    "    json.dump(augmentation_reports, metrics)\n",
    "# print(\"*\" * 40)\n",
    "# print(class_reports)\n",
    "# print(\"*\" * 40)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[3 2 2 3 1 3 4 5 4 3 1 3 5 2 5 5 2 5 2 4 2 1 3 3 1 3 4 2 1 1 1 3 5 1 4 4 5\n",
      " 2 4 3 4 3 1 1 4 1 1 3 3 3 2 2 5 5 2 1 4 5 1 2 3 4 1 4 5 4 2 5 1 1 2 5 1 1\n",
      " 1 4 4 1 3 3 4 5 2 2 4 3 4 5 3 1 5 2 5 3 5 1 2 2 2 5 4 5 5]\n"
     ]
    }
   ],
   "source": [
    "y_test_transformed = y_test\n",
    "y_train_transformed = y_train\n",
    "label = 0\n",
    "\n",
    "selected_ytest = (y_test_transformed == label)\n",
    "selected_ytrain = (y_train_transformed == label)\n",
    "\n",
    "notSelected_ytest = (y_test_transformed != label)\n",
    "notSelected_ytrain = (y_train_transformed != label)\n",
    "\n",
    "\n",
    "print(y_test[selected_ytest])\n",
    "print(y_test[notSelected_ytest])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "# Change the labels to 0 for augmented class and 1 for other class\n",
    "labels = []\n",
    "for item in notSelected_ytrain:\n",
    "    if item == 1:\n",
    "        labels.append(1)        \n",
    "    else:\n",
    "        item = 0\n",
    "        labels.append(item)\n",
    "\n",
    "print(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ytest: [0 1 2 3 4 5]\n",
      "ytrain: [0 1 2 3 4 5]\n",
      "Class distribution in y_test: [16 23 20 20 19 21]\n",
      "Class distribution in y_train: [84 77 80 72 81 79]\n",
      "Class: 0\n",
      " === Augmentation: UnnamedMultiply === \n",
      "Classes test : [0 3 2 2 3 1 3 4 5 4 3 1 3 0 5 2 5 5 2 5 2 4 2 1 3 0 3 1 3 4 2 1 1 1 3 5 1\n",
      " 0 4 0 4 5 2 4 3 4 0 3 1 0 1 4 1 0 1 3 3 3 2 2 0 5 5 2 1 4 5 1 0 2 3 4 1 4\n",
      " 5 4 2 5 0 1 1 2 5 0 1 1 1 4 4 1 3 3 4 0 5 2 2 0 4 3 4 5 3 1 5 2 0 5 3 5 1\n",
      " 2 2 2 0 5 4 5 5]\n",
      "Classes pred : [1 4 5 2 0 2 0 2 5 2 2 3 0 1 5 5 4 0 0 5 1 2 2 2 0 3 3 0 0 4 3 5 0 0 0 4 1\n",
      " 5 4 1 0 4 1 0 0 2 5 0 1 0 0 4 0 2 0 0 0 5 2 0 0 2 2 5 5 2 2 0 0 3 0 5 5 4\n",
      " 5 5 4 2 5 0 0 4 5 0 0 0 0 4 0 1 2 0 4 5 2 4 2 0 5 5 5 4 0 1 3 0 0 2 1 3 1\n",
      " 5 5 1 1 2 5 4 4]\n",
      " === Augmentation: UnnamedFlipud === \n",
      "Classes test : [0 3 2 2 3 1 3 4 5 4 3 1 3 0 5 2 5 5 2 5 2 4 2 1 3 0 3 1 3 4 2 1 1 1 3 5 1\n",
      " 0 4 0 4 5 2 4 3 4 0 3 1 0 1 4 1 0 1 3 3 3 2 2 0 5 5 2 1 4 5 1 0 2 3 4 1 4\n",
      " 5 4 2 5 0 1 1 2 5 0 1 1 1 4 4 1 3 3 4 0 5 2 2 0 4 3 4 5 3 1 5 2 0 5 3 5 1\n",
      " 2 2 2 0 5 4 5 5]\n",
      "Classes pred : [0 5 4 5 0 4 0 5 5 4 2 0 0 0 5 5 4 1 0 5 0 5 0 3 0 5 0 0 0 4 2 0 0 0 0 5 0\n",
      " 5 4 3 2 4 4 0 0 2 5 0 1 0 0 4 0 2 2 3 0 0 2 0 0 0 2 4 2 0 5 0 0 0 2 2 1 4\n",
      " 5 5 4 2 3 0 0 0 0 0 0 0 0 4 0 0 0 0 0 1 0 4 0 0 0 2 5 4 3 0 2 0 0 2 1 3 0\n",
      " 5 5 3 1 5 1 4 4]\n",
      " === Augmentation: UnnamedFliplr === \n",
      "Classes test : [0 3 2 2 3 1 3 4 5 4 3 1 3 0 5 2 5 5 2 5 2 4 2 1 3 0 3 1 3 4 2 1 1 1 3 5 1\n",
      " 0 4 0 4 5 2 4 3 4 0 3 1 0 1 4 1 0 1 3 3 3 2 2 0 5 5 2 1 4 5 1 0 2 3 4 1 4\n",
      " 5 4 2 5 0 1 1 2 5 0 1 1 1 4 4 1 3 3 4 0 5 2 2 0 4 3 4 5 3 1 5 2 0 5 3 5 1\n",
      " 2 2 2 0 5 4 5 5]\n",
      "Classes pred : [3 5 5 5 0 2 0 2 5 5 0 0 0 0 0 5 4 5 0 2 0 2 0 2 0 2 0 0 0 4 3 0 0 0 0 5 0\n",
      " 2 4 0 0 4 4 5 0 4 0 0 0 0 0 4 2 0 5 0 0 0 2 2 1 5 5 5 2 2 5 0 0 0 2 0 2 4\n",
      " 5 5 0 2 0 5 0 0 5 0 0 3 0 4 0 3 0 0 4 0 0 4 0 5 1 0 5 4 0 4 2 0 0 1 0 2 0\n",
      " 5 5 0 0 2 3 4 4]\n",
      "Class: 1\n",
      " === Augmentation: UnnamedMultiply === \n",
      "Classes test : [0 3 2 2 3 1 3 4 5 4 3 1 3 0 5 2 5 5 2 5 2 4 2 1 3 0 3 1 3 4 2 1 1 1 3 5 1\n",
      " 0 4 0 4 5 2 4 3 4 0 3 1 0 1 4 1 0 1 3 3 3 2 2 0 5 5 2 1 4 5 1 0 2 3 4 1 4\n",
      " 5 4 2 5 0 1 1 2 5 0 1 1 1 4 4 1 3 3 4 0 5 2 2 0 4 3 4 5 3 1 5 2 0 5 3 5 1\n",
      " 2 2 2 0 5 4 5 5]\n",
      "Classes pred : [0 3 2 0 3 4 3 4 5 4 0 4 0 0 5 5 2 5 0 3 0 0 5 0 3 0 3 3 3 4 0 3 0 3 3 4 2\n",
      " 5 4 3 2 4 4 3 3 2 3 3 0 0 0 4 4 0 0 3 3 2 4 3 3 4 4 4 3 0 2 3 0 0 5 5 5 4\n",
      " 5 5 0 2 3 0 1 4 0 3 0 3 3 4 0 0 5 3 5 2 3 4 3 3 5 5 4 4 3 0 2 3 0 0 0 0 1\n",
      " 5 5 3 1 2 4 4 4]\n",
      " === Augmentation: UnnamedFlipud === \n",
      "Classes test : [0 3 2 2 3 1 3 4 5 4 3 1 3 0 5 2 5 5 2 5 2 4 2 1 3 0 3 1 3 4 2 1 1 1 3 5 1\n",
      " 0 4 0 4 5 2 4 3 4 0 3 1 0 1 4 1 0 1 3 3 3 2 2 0 5 5 2 1 4 5 1 0 2 3 4 1 4\n",
      " 5 4 2 5 0 1 1 2 5 0 1 1 1 4 4 1 3 3 4 0 5 2 2 0 4 3 4 5 3 1 5 2 0 5 3 5 1\n",
      " 2 2 2 0 5 4 5 5]\n",
      "Classes pred : [0 5 4 5 0 4 0 5 5 4 2 0 0 0 5 5 4 1 0 5 0 5 0 3 0 5 0 0 0 4 2 0 0 0 0 5 0\n",
      " 5 4 3 2 4 4 0 0 2 5 0 1 0 0 4 0 2 2 3 0 0 2 0 0 0 2 4 2 0 5 0 0 0 2 2 1 4\n",
      " 5 5 4 2 3 0 0 0 0 0 0 0 0 4 0 0 0 0 0 1 0 4 0 0 0 2 5 4 3 0 2 0 0 2 1 3 0\n",
      " 5 5 3 1 5 1 4 4]\n",
      " === Augmentation: UnnamedFliplr === \n",
      "Classes test : [0 3 2 2 3 1 3 4 5 4 3 1 3 0 5 2 5 5 2 5 2 4 2 1 3 0 3 1 3 4 2 1 1 1 3 5 1\n",
      " 0 4 0 4 5 2 4 3 4 0 3 1 0 1 4 1 0 1 3 3 3 2 2 0 5 5 2 1 4 5 1 0 2 3 4 1 4\n",
      " 5 4 2 5 0 1 1 2 5 0 1 1 1 4 4 1 3 3 4 0 5 2 2 0 4 3 4 5 3 1 5 2 0 5 3 5 1\n",
      " 2 2 2 0 5 4 5 5]\n",
      "Classes pred : [1 5 4 2 1 0 1 0 5 4 5 4 1 1 5 5 2 2 1 5 0 4 5 3 1 5 1 1 1 4 2 1 1 1 1 4 0\n",
      " 5 4 1 0 4 2 1 1 5 0 1 1 1 0 4 0 3 1 1 0 1 0 1 1 5 5 5 1 2 5 1 1 0 5 5 5 4\n",
      " 0 5 3 2 0 1 1 2 1 1 1 1 1 4 0 1 0 1 5 5 1 4 0 1 5 5 5 4 1 5 0 1 3 4 1 2 1\n",
      " 5 2 2 1 4 5 4 4]\n",
      "Class: 2\n",
      " === Augmentation: UnnamedMultiply === \n",
      "Classes test : [0 3 2 2 3 1 3 4 5 4 3 1 3 0 5 2 5 5 2 5 2 4 2 1 3 0 3 1 3 4 2 1 1 1 3 5 1\n",
      " 0 4 0 4 5 2 4 3 4 0 3 1 0 1 4 1 0 1 3 3 3 2 2 0 5 5 2 1 4 5 1 0 2 3 4 1 4\n",
      " 5 4 2 5 0 1 1 2 5 0 1 1 1 4 4 1 3 3 4 0 5 2 2 0 4 3 4 5 3 1 5 2 0 5 3 5 1\n",
      " 2 2 2 0 5 4 5 5]\n",
      "Classes pred : [1 4 4 5 2 5 2 5 4 4 5 2 2 2 5 5 4 5 2 5 0 4 0 3 2 4 2 2 2 4 2 2 2 2 2 4 0\n",
      " 0 4 2 1 4 5 1 2 5 5 2 2 0 2 4 0 3 5 2 2 2 3 2 2 4 5 4 2 0 5 2 2 0 5 1 5 4\n",
      " 5 5 4 2 2 2 2 3 2 2 2 0 0 4 1 2 2 2 4 2 2 4 2 2 3 5 5 4 2 0 2 2 0 4 2 0 2\n",
      " 4 1 0 2 1 5 4 4]\n",
      " === Augmentation: UnnamedFlipud === \n",
      "Classes test : [0 3 2 2 3 1 3 4 5 4 3 1 3 0 5 2 5 5 2 5 2 4 2 1 3 0 3 1 3 4 2 1 1 1 3 5 1\n",
      " 0 4 0 4 5 2 4 3 4 0 3 1 0 1 4 1 0 1 3 3 3 2 2 0 5 5 2 1 4 5 1 0 2 3 4 1 4\n",
      " 5 4 2 5 0 1 1 2 5 0 1 1 1 4 4 1 3 3 4 0 5 2 2 0 4 3 4 5 3 1 5 2 0 5 3 5 1\n",
      " 2 2 2 0 5 4 5 5]\n",
      "Classes pred : [0 5 4 5 0 4 0 5 5 4 2 0 0 0 5 5 4 1 0 5 0 5 0 3 0 5 0 0 0 4 2 0 0 0 0 5 0\n",
      " 5 4 3 2 4 4 0 0 2 5 0 1 0 0 4 0 2 2 3 0 0 2 0 0 0 2 4 2 0 5 0 0 0 2 2 1 4\n",
      " 5 5 4 2 3 0 0 0 0 0 0 0 0 4 0 0 0 0 0 1 0 4 0 0 0 2 5 4 3 0 2 0 0 2 1 3 0\n",
      " 5 5 3 1 5 1 4 4]\n",
      " === Augmentation: UnnamedFliplr === \n",
      "Classes test : [0 3 2 2 3 1 3 4 5 4 3 1 3 0 5 2 5 5 2 5 2 4 2 1 3 0 3 1 3 4 2 1 1 1 3 5 1\n",
      " 0 4 0 4 5 2 4 3 4 0 3 1 0 1 4 1 0 1 3 3 3 2 2 0 5 5 2 1 4 5 1 0 2 3 4 1 4\n",
      " 5 4 2 5 0 1 1 2 5 0 1 1 1 4 4 1 3 3 4 0 5 2 2 0 4 3 4 5 3 1 5 2 0 5 3 5 1\n",
      " 2 2 2 0 5 4 5 5]\n",
      "Classes pred : [0 5 5 2 0 4 0 5 4 4 2 3 0 0 1 5 4 0 0 5 0 1 2 2 0 2 0 0 0 4 2 0 0 0 0 4 5\n",
      " 5 4 0 0 4 0 0 0 5 5 0 1 0 0 4 0 0 2 3 0 0 4 2 0 5 2 5 2 2 5 0 0 0 2 5 5 2\n",
      " 5 5 2 5 3 0 0 0 0 3 0 0 0 4 0 0 0 0 4 0 0 4 0 0 4 5 5 4 3 4 2 3 0 2 1 2 0\n",
      " 4 5 0 0 3 3 5 4]\n",
      "Class: 3\n",
      " === Augmentation: UnnamedMultiply === \n",
      "Classes test : [0 3 2 2 3 1 3 4 5 4 3 1 3 0 5 2 5 5 2 5 2 4 2 1 3 0 3 1 3 4 2 1 1 1 3 5 1\n",
      " 0 4 0 4 5 2 4 3 4 0 3 1 0 1 4 1 0 1 3 3 3 2 2 0 5 5 2 1 4 5 1 0 2 3 4 1 4\n",
      " 5 4 2 5 0 1 1 2 5 0 1 1 1 4 4 1 3 3 4 0 5 2 2 0 4 3 4 5 3 1 5 2 0 5 3 5 1\n",
      " 2 2 2 0 5 4 5 5]\n",
      "Classes pred : [0 0 0 0 0 0 0 0 3 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0]\n",
      " === Augmentation: UnnamedFlipud === \n",
      "Classes test : [0 3 2 2 3 1 3 4 5 4 3 1 3 0 5 2 5 5 2 5 2 4 2 1 3 0 3 1 3 4 2 1 1 1 3 5 1\n",
      " 0 4 0 4 5 2 4 3 4 0 3 1 0 1 4 1 0 1 3 3 3 2 2 0 5 5 2 1 4 5 1 0 2 3 4 1 4\n",
      " 5 4 2 5 0 1 1 2 5 0 1 1 1 4 4 1 3 3 4 0 5 2 2 0 4 3 4 5 3 1 5 2 0 5 3 5 1\n",
      " 2 2 2 0 5 4 5 5]\n",
      "Classes pred : [0 5 4 5 0 4 0 5 5 4 2 0 0 0 5 5 4 1 0 5 0 5 0 3 0 5 0 0 0 4 2 0 0 0 0 5 0\n",
      " 5 4 3 2 4 4 0 0 2 5 0 1 0 0 4 0 2 2 3 0 0 2 0 0 0 2 4 2 0 5 0 0 0 2 2 1 4\n",
      " 5 5 4 2 3 0 0 0 0 0 0 0 0 4 0 0 0 0 0 1 0 4 0 0 0 2 5 4 3 0 2 0 0 2 1 3 0\n",
      " 5 5 3 1 5 1 4 4]\n",
      " === Augmentation: UnnamedFliplr === \n",
      "Classes test : [0 3 2 2 3 1 3 4 5 4 3 1 3 0 5 2 5 5 2 5 2 4 2 1 3 0 3 1 3 4 2 1 1 1 3 5 1\n",
      " 0 4 0 4 5 2 4 3 4 0 3 1 0 1 4 1 0 1 3 3 3 2 2 0 5 5 2 1 4 5 1 0 2 3 4 1 4\n",
      " 5 4 2 5 0 1 1 2 5 0 1 1 1 4 4 1 3 3 4 0 5 2 2 0 4 3 4 5 3 1 5 2 0 5 3 5 1\n",
      " 2 2 2 0 5 4 5 5]\n",
      "Classes pred : [0 5 4 5 0 4 0 5 5 4 2 0 0 0 5 5 4 1 0 5 0 5 0 3 0 5 0 0 0 4 2 0 0 0 0 5 0\n",
      " 5 4 3 2 4 4 0 0 2 5 0 1 0 0 4 0 2 2 3 0 0 2 0 0 0 2 4 2 0 5 0 0 0 2 2 1 4\n",
      " 5 5 4 2 3 0 0 0 0 0 0 0 0 4 0 0 0 0 0 1 0 4 0 0 0 2 5 4 3 0 2 0 0 2 1 3 0\n",
      " 5 5 3 1 5 1 4 4]\n",
      "Class: 4\n",
      " === Augmentation: UnnamedMultiply === \n",
      "Classes test : [0 3 2 2 3 1 3 4 5 4 3 1 3 0 5 2 5 5 2 5 2 4 2 1 3 0 3 1 3 4 2 1 1 1 3 5 1\n",
      " 0 4 0 4 5 2 4 3 4 0 3 1 0 1 4 1 0 1 3 3 3 2 2 0 5 5 2 1 4 5 1 0 2 3 4 1 4\n",
      " 5 4 2 5 0 1 1 2 5 0 1 1 1 4 4 1 3 3 4 0 5 2 2 0 4 3 4 5 3 1 5 2 0 5 3 5 1\n",
      " 2 2 2 0 5 4 5 5]\n",
      "Classes pred : [3 5 4 0 3 2 0 5 5 4 0 0 0 0 5 5 4 5 0 2 0 2 2 3 0 1 0 0 0 4 2 0 0 0 0 4 0\n",
      " 3 4 0 5 4 2 0 0 4 5 0 1 0 0 4 0 1 2 3 0 0 1 0 0 2 2 4 0 0 2 0 0 2 1 2 5 4\n",
      " 5 2 2 2 0 0 0 0 0 0 3 3 0 4 2 3 1 0 2 3 3 4 3 0 5 3 1 4 0 1 2 0 0 0 1 3 0\n",
      " 4 5 2 0 5 2 4 4]\n",
      " === Augmentation: UnnamedFlipud === \n",
      "Classes test : [0 3 2 2 3 1 3 4 5 4 3 1 3 0 5 2 5 5 2 5 2 4 2 1 3 0 3 1 3 4 2 1 1 1 3 5 1\n",
      " 0 4 0 4 5 2 4 3 4 0 3 1 0 1 4 1 0 1 3 3 3 2 2 0 5 5 2 1 4 5 1 0 2 3 4 1 4\n",
      " 5 4 2 5 0 1 1 2 5 0 1 1 1 4 4 1 3 3 4 0 5 2 2 0 4 3 4 5 3 1 5 2 0 5 3 5 1\n",
      " 2 2 2 0 5 4 5 5]\n",
      "Classes pred : [0 5 4 5 0 4 0 5 5 4 2 0 0 0 5 5 4 1 0 5 0 5 0 3 0 5 0 0 0 4 2 0 0 0 0 5 0\n",
      " 5 4 3 2 4 4 0 0 2 5 0 1 0 0 4 0 2 2 3 0 0 2 0 0 0 2 4 2 0 5 0 0 0 2 2 1 4\n",
      " 5 5 4 2 3 0 0 0 0 0 0 0 0 4 0 0 0 0 0 1 0 4 0 0 0 2 5 4 3 0 2 0 0 2 1 3 0\n",
      " 5 5 3 1 5 1 4 4]\n",
      " === Augmentation: UnnamedFliplr === \n",
      "Classes test : [0 3 2 2 3 1 3 4 5 4 3 1 3 0 5 2 5 5 2 5 2 4 2 1 3 0 3 1 3 4 2 1 1 1 3 5 1\n",
      " 0 4 0 4 5 2 4 3 4 0 3 1 0 1 4 1 0 1 3 3 3 2 2 0 5 5 2 1 4 5 1 0 2 3 4 1 4\n",
      " 5 4 2 5 0 1 1 2 5 0 1 1 1 4 4 1 3 3 4 0 5 2 2 0 4 3 4 5 3 1 5 2 0 5 3 5 1\n",
      " 2 2 2 0 5 4 5 5]\n",
      "Classes pred : [0 2 4 3 0 4 0 2 4 2 2 2 0 0 2 5 4 5 0 5 0 4 2 2 0 5 0 0 0 4 0 0 0 0 0 4 0\n",
      " 5 4 0 1 4 3 0 0 1 2 0 0 0 0 4 3 0 0 0 3 0 2 0 0 5 2 5 3 2 5 0 0 0 5 5 5 4\n",
      " 5 5 2 5 0 0 0 1 0 0 0 0 0 4 0 0 2 0 2 0 0 4 3 0 2 5 5 4 0 2 2 0 0 2 0 4 0\n",
      " 2 5 0 0 2 2 4 4]\n",
      "Class: 5\n",
      " === Augmentation: UnnamedMultiply === \n",
      "Classes test : [0 3 2 2 3 1 3 4 5 4 3 1 3 0 5 2 5 5 2 5 2 4 2 1 3 0 3 1 3 4 2 1 1 1 3 5 1\n",
      " 0 4 0 4 5 2 4 3 4 0 3 1 0 1 4 1 0 1 3 3 3 2 2 0 5 5 2 1 4 5 1 0 2 3 4 1 4\n",
      " 5 4 2 5 0 1 1 2 5 0 1 1 1 4 4 1 3 3 4 0 5 2 2 0 4 3 4 5 3 1 5 2 0 5 3 5 1\n",
      " 2 2 2 0 5 4 5 5]\n",
      "Classes pred : [0 2 5 2 0 4 0 5 5 4 1 2 0 0 5 2 4 5 0 2 0 5 4 0 0 5 0 0 0 2 2 0 0 0 0 4 0\n",
      " 2 4 0 0 4 2 0 0 2 2 0 3 3 0 4 0 1 0 3 0 0 4 0 0 5 2 4 2 2 5 0 0 0 2 5 5 2\n",
      " 2 2 3 2 3 0 0 0 0 0 0 0 1 4 2 0 0 0 0 0 0 0 0 0 1 2 5 4 3 0 2 0 3 2 3 2 0\n",
      " 5 5 0 0 5 5 4 4]\n",
      " === Augmentation: UnnamedFlipud === \n",
      "Classes test : [0 3 2 2 3 1 3 4 5 4 3 1 3 0 5 2 5 5 2 5 2 4 2 1 3 0 3 1 3 4 2 1 1 1 3 5 1\n",
      " 0 4 0 4 5 2 4 3 4 0 3 1 0 1 4 1 0 1 3 3 3 2 2 0 5 5 2 1 4 5 1 0 2 3 4 1 4\n",
      " 5 4 2 5 0 1 1 2 5 0 1 1 1 4 4 1 3 3 4 0 5 2 2 0 4 3 4 5 3 1 5 2 0 5 3 5 1\n",
      " 2 2 2 0 5 4 5 5]\n",
      "Classes pred : [0 5 4 5 0 4 0 5 5 4 2 0 0 0 5 5 4 1 0 5 0 5 0 3 0 5 0 0 0 4 2 0 0 0 0 5 0\n",
      " 5 4 3 2 4 4 0 0 2 5 0 1 0 0 4 0 2 2 3 0 0 2 0 0 0 2 4 2 0 5 0 0 0 2 2 1 4\n",
      " 5 5 4 2 3 0 0 0 0 0 0 0 0 4 0 0 0 0 0 1 0 4 0 0 0 2 5 4 3 0 2 0 0 2 1 3 0\n",
      " 5 5 3 1 5 1 4 4]\n",
      " === Augmentation: UnnamedFliplr === \n",
      "Classes test : [0 3 2 2 3 1 3 4 5 4 3 1 3 0 5 2 5 5 2 5 2 4 2 1 3 0 3 1 3 4 2 1 1 1 3 5 1\n",
      " 0 4 0 4 5 2 4 3 4 0 3 1 0 1 4 1 0 1 3 3 3 2 2 0 5 5 2 1 4 5 1 0 2 3 4 1 4\n",
      " 5 4 2 5 0 1 1 2 5 0 1 1 1 4 4 1 3 3 4 0 5 2 2 0 4 3 4 5 3 1 5 2 0 5 3 5 1\n",
      " 2 2 2 0 5 4 5 5]\n",
      "Classes pred : [0 5 4 5 0 4 0 5 5 4 2 0 0 0 5 5 4 1 0 5 0 5 0 3 0 5 0 0 0 4 2 0 0 0 0 5 0\n",
      " 5 4 3 2 4 4 0 0 2 5 0 1 0 0 4 0 2 2 3 0 0 2 0 0 0 2 4 2 0 5 0 0 0 2 2 1 4\n",
      " 5 5 4 2 3 0 0 0 0 0 0 0 0 4 0 0 0 0 0 1 0 4 0 0 0 2 5 4 3 0 2 0 0 2 1 3 0\n",
      " 5 5 3 1 5 1 4 4]\n",
      "########################################\n",
      "\\Class:  == Class_0 ==\n",
      "\n",
      "========================================\n",
      "Augmentation UnnamedMultiply Classification Report:\n",
      "0: {'precision': 0.15789473684210525, 'recall': 0.375, 'f1-score': 0.22222222222222218, 'support': 16}\n",
      "1: {'precision': 0.38461538461538464, 'recall': 0.21739130434782608, 'f1-score': 0.27777777777777773, 'support': 23}\n",
      "2: {'precision': 0.19047619047619047, 'recall': 0.2, 'f1-score': 0.1951219512195122, 'support': 20}\n",
      "3: {'precision': 0.14285714285714285, 'recall': 0.05, 'f1-score': 0.07407407407407408, 'support': 20}\n",
      "4: {'precision': 0.375, 'recall': 0.3157894736842105, 'f1-score': 0.34285714285714286, 'support': 19}\n",
      "5: {'precision': 0.20833333333333334, 'recall': 0.23809523809523808, 'f1-score': 0.22222222222222224, 'support': 21}\n",
      "macro avg: {'precision': 0.24319613135402607, 'recall': 0.23271266935454582, 'f1-score': 0.22237923172882523, 'support': 119}\n",
      "weighted avg: {'precision': 0.24822803615373276, 'recall': 0.226890756302521, 'f1-score': 0.2227673725316685, 'support': 119}\n",
      "========================================\n",
      "Augmentation UnnamedFlipud Classification Report:\n",
      "0: {'precision': 0.14814814814814814, 'recall': 0.5, 'f1-score': 0.22857142857142856, 'support': 16}\n",
      "1: {'precision': 0.2857142857142857, 'recall': 0.08695652173913043, 'f1-score': 0.13333333333333333, 'support': 23}\n",
      "2: {'precision': 0.13333333333333333, 'recall': 0.1, 'f1-score': 0.1142857142857143, 'support': 20}\n",
      "3: {'precision': 0.2857142857142857, 'recall': 0.1, 'f1-score': 0.14814814814814817, 'support': 20}\n",
      "4: {'precision': 0.35294117647058826, 'recall': 0.3157894736842105, 'f1-score': 0.33333333333333337, 'support': 19}\n",
      "5: {'precision': 0.3684210526315789, 'recall': 0.3333333333333333, 'f1-score': 0.35, 'support': 21}\n",
      "macro avg: {'precision': 0.26237871366870336, 'recall': 0.239346554792779, 'f1-score': 0.21794532627865962, 'support': 119}\n",
      "weighted avg: {'precision': 0.26693677126853493, 'recall': 0.226890756302521, 'f1-score': 0.21559512693966476, 'support': 119}\n",
      "========================================\n",
      "Augmentation UnnamedFliplr Classification Report:\n",
      "0: {'precision': 0.19642857142857142, 'recall': 0.6875, 'f1-score': 0.3055555555555555, 'support': 16}\n",
      "1: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 23}\n",
      "2: {'precision': 0.1111111111111111, 'recall': 0.1, 'f1-score': 0.10526315789473685, 'support': 20}\n",
      "3: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 20}\n",
      "4: {'precision': 0.4666666666666667, 'recall': 0.3684210526315789, 'f1-score': 0.4117647058823529, 'support': 19}\n",
      "5: {'precision': 0.36363636363636365, 'recall': 0.38095238095238093, 'f1-score': 0.37209302325581395, 'support': 21}\n",
      "macro avg: {'precision': 0.18964045214045214, 'recall': 0.2561455722639933, 'f1-score': 0.1991127404314099, 'support': 119}\n",
      "weighted avg: {'precision': 0.18376562746310646, 'recall': 0.23529411764705882, 'f1-score': 0.19018180627664222, 'support': 119}\n",
      "========================================\n",
      "########################################\n",
      "########################################\n",
      "\\Class:  == Class_1 ==\n",
      "\n",
      "========================================\n",
      "Augmentation UnnamedMultiply Classification Report:\n",
      "0: {'precision': 0.22580645161290322, 'recall': 0.4375, 'f1-score': 0.2978723404255319, 'support': 16}\n",
      "1: {'precision': 0.6666666666666666, 'recall': 0.08695652173913043, 'f1-score': 0.15384615384615383, 'support': 23}\n",
      "2: {'precision': 0.09090909090909091, 'recall': 0.05, 'f1-score': 0.06451612903225806, 'support': 20}\n",
      "3: {'precision': 0.3939393939393939, 'recall': 0.65, 'f1-score': 0.490566037735849, 'support': 20}\n",
      "4: {'precision': 0.375, 'recall': 0.47368421052631576, 'f1-score': 0.4186046511627907, 'support': 19}\n",
      "5: {'precision': 0.23529411764705882, 'recall': 0.19047619047619047, 'f1-score': 0.21052631578947367, 'support': 21}\n",
      "macro avg: {'precision': 0.33126928679585227, 'recall': 0.31476948712360614, 'f1-score': 0.27265527133200956, 'support': 119}\n",
      "weighted avg: {'precision': 0.342095653165527, 'recall': 0.3025210084033613, 'f1-score': 0.2670638934815476, 'support': 119}\n",
      "========================================\n",
      "Augmentation UnnamedFlipud Classification Report:\n",
      "0: {'precision': 0.14814814814814814, 'recall': 0.5, 'f1-score': 0.22857142857142856, 'support': 16}\n",
      "1: {'precision': 0.2857142857142857, 'recall': 0.08695652173913043, 'f1-score': 0.13333333333333333, 'support': 23}\n",
      "2: {'precision': 0.13333333333333333, 'recall': 0.1, 'f1-score': 0.1142857142857143, 'support': 20}\n",
      "3: {'precision': 0.2857142857142857, 'recall': 0.1, 'f1-score': 0.14814814814814817, 'support': 20}\n",
      "4: {'precision': 0.35294117647058826, 'recall': 0.3157894736842105, 'f1-score': 0.33333333333333337, 'support': 19}\n",
      "5: {'precision': 0.3684210526315789, 'recall': 0.3333333333333333, 'f1-score': 0.35, 'support': 21}\n",
      "macro avg: {'precision': 0.26237871366870336, 'recall': 0.239346554792779, 'f1-score': 0.21794532627865962, 'support': 119}\n",
      "weighted avg: {'precision': 0.26693677126853493, 'recall': 0.226890756302521, 'f1-score': 0.21559512693966476, 'support': 119}\n",
      "========================================\n",
      "Augmentation UnnamedFliplr Classification Report:\n",
      "0: {'precision': 0.11764705882352941, 'recall': 0.125, 'f1-score': 0.12121212121212122, 'support': 16}\n",
      "1: {'precision': 0.3409090909090909, 'recall': 0.6521739130434783, 'f1-score': 0.44776119402985076, 'support': 23}\n",
      "2: {'precision': 0.5454545454545454, 'recall': 0.3, 'f1-score': 0.3870967741935483, 'support': 20}\n",
      "3: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 20}\n",
      "4: {'precision': 0.4117647058823529, 'recall': 0.3684210526315789, 'f1-score': 0.3888888888888889, 'support': 19}\n",
      "5: {'precision': 0.23076923076923078, 'recall': 0.2857142857142857, 'f1-score': 0.25531914893617025, 'support': 21}\n",
      "macro avg: {'precision': 0.2744241053064582, 'recall': 0.28855154189822385, 'f1-score': 0.26671302121009655, 'support': 119}\n",
      "weighted avg: {'precision': 0.2798490436898742, 'recall': 0.3025210084033613, 'f1-score': 0.2750456126260499, 'support': 119}\n",
      "========================================\n",
      "########################################\n",
      "########################################\n",
      "\\Class:  == Class_2 ==\n",
      "\n",
      "========================================\n",
      "Augmentation UnnamedMultiply Classification Report:\n",
      "0: {'precision': 0.21428571428571427, 'recall': 0.1875, 'f1-score': 0.19999999999999998, 'support': 16}\n",
      "1: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 23}\n",
      "2: {'precision': 0.10416666666666667, 'recall': 0.25, 'f1-score': 0.14705882352941177, 'support': 20}\n",
      "3: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 20}\n",
      "4: {'precision': 0.3333333333333333, 'recall': 0.42105263157894735, 'f1-score': 0.372093023255814, 'support': 19}\n",
      "5: {'precision': 0.2857142857142857, 'recall': 0.2857142857142857, 'f1-score': 0.2857142857142857, 'support': 21}\n",
      "macro avg: {'precision': 0.15624999999999997, 'recall': 0.1907111528822055, 'f1-score': 0.1674776887499186, 'support': 119}\n",
      "weighted avg: {'precision': 0.14995998399359745, 'recall': 0.18487394957983194, 'f1-score': 0.16143650346595548, 'support': 119}\n",
      "========================================\n",
      "Augmentation UnnamedFlipud Classification Report:\n",
      "0: {'precision': 0.14814814814814814, 'recall': 0.5, 'f1-score': 0.22857142857142856, 'support': 16}\n",
      "1: {'precision': 0.2857142857142857, 'recall': 0.08695652173913043, 'f1-score': 0.13333333333333333, 'support': 23}\n",
      "2: {'precision': 0.13333333333333333, 'recall': 0.1, 'f1-score': 0.1142857142857143, 'support': 20}\n",
      "3: {'precision': 0.2857142857142857, 'recall': 0.1, 'f1-score': 0.14814814814814817, 'support': 20}\n",
      "4: {'precision': 0.35294117647058826, 'recall': 0.3157894736842105, 'f1-score': 0.33333333333333337, 'support': 19}\n",
      "5: {'precision': 0.3684210526315789, 'recall': 0.3333333333333333, 'f1-score': 0.35, 'support': 21}\n",
      "macro avg: {'precision': 0.26237871366870336, 'recall': 0.239346554792779, 'f1-score': 0.21794532627865962, 'support': 119}\n",
      "weighted avg: {'precision': 0.26693677126853493, 'recall': 0.226890756302521, 'f1-score': 0.21559512693966476, 'support': 119}\n",
      "========================================\n",
      "Augmentation UnnamedFliplr Classification Report:\n",
      "0: {'precision': 0.21568627450980393, 'recall': 0.6875, 'f1-score': 0.3283582089552239, 'support': 16}\n",
      "1: {'precision': 0.25, 'recall': 0.043478260869565216, 'f1-score': 0.07407407407407408, 'support': 23}\n",
      "2: {'precision': 0.29411764705882354, 'recall': 0.25, 'f1-score': 0.27027027027027023, 'support': 20}\n",
      "3: {'precision': 0.25, 'recall': 0.1, 'f1-score': 0.14285714285714288, 'support': 20}\n",
      "4: {'precision': 0.3888888888888889, 'recall': 0.3684210526315789, 'f1-score': 0.37837837837837834, 'support': 19}\n",
      "5: {'precision': 0.2857142857142857, 'recall': 0.2857142857142857, 'f1-score': 0.2857142857142857, 'support': 21}\n",
      "macro avg: {'precision': 0.28073451602863364, 'recall': 0.2891855998692383, 'f1-score': 0.24660872670822917, 'support': 119}\n",
      "weighted avg: {'precision': 0.2812791783380019, 'recall': 0.2689075630252101, 'f1-score': 0.23873254200609023, 'support': 119}\n",
      "========================================\n",
      "########################################\n",
      "########################################\n",
      "\\Class:  == Class_3 ==\n",
      "\n",
      "========================================\n",
      "Augmentation UnnamedMultiply Classification Report:\n",
      "0: {'precision': 0.14414414414414414, 'recall': 1.0, 'f1-score': 0.25196850393700787, 'support': 16}\n",
      "1: {'precision': 0.5, 'recall': 0.13043478260869565, 'f1-score': 0.20689655172413793, 'support': 23}\n",
      "2: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 20}\n",
      "3: {'precision': 0.5, 'recall': 0.05, 'f1-score': 0.09090909090909091, 'support': 20}\n",
      "4: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 19}\n",
      "5: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 21}\n",
      "macro avg: {'precision': 0.19069069069069067, 'recall': 0.1967391304347826, 'f1-score': 0.09162902442837279, 'support': 119}\n",
      "weighted avg: {'precision': 0.2000529941706412, 'recall': 0.16806722689075632, 'f1-score': 0.08914536614142116, 'support': 119}\n",
      "========================================\n",
      "Augmentation UnnamedFlipud Classification Report:\n",
      "0: {'precision': 0.14814814814814814, 'recall': 0.5, 'f1-score': 0.22857142857142856, 'support': 16}\n",
      "1: {'precision': 0.2857142857142857, 'recall': 0.08695652173913043, 'f1-score': 0.13333333333333333, 'support': 23}\n",
      "2: {'precision': 0.13333333333333333, 'recall': 0.1, 'f1-score': 0.1142857142857143, 'support': 20}\n",
      "3: {'precision': 0.2857142857142857, 'recall': 0.1, 'f1-score': 0.14814814814814817, 'support': 20}\n",
      "4: {'precision': 0.35294117647058826, 'recall': 0.3157894736842105, 'f1-score': 0.33333333333333337, 'support': 19}\n",
      "5: {'precision': 0.3684210526315789, 'recall': 0.3333333333333333, 'f1-score': 0.35, 'support': 21}\n",
      "macro avg: {'precision': 0.26237871366870336, 'recall': 0.239346554792779, 'f1-score': 0.21794532627865962, 'support': 119}\n",
      "weighted avg: {'precision': 0.26693677126853493, 'recall': 0.226890756302521, 'f1-score': 0.21559512693966476, 'support': 119}\n",
      "========================================\n",
      "Augmentation UnnamedFliplr Classification Report:\n",
      "0: {'precision': 0.14814814814814814, 'recall': 0.5, 'f1-score': 0.22857142857142856, 'support': 16}\n",
      "1: {'precision': 0.2857142857142857, 'recall': 0.08695652173913043, 'f1-score': 0.13333333333333333, 'support': 23}\n",
      "2: {'precision': 0.13333333333333333, 'recall': 0.1, 'f1-score': 0.1142857142857143, 'support': 20}\n",
      "3: {'precision': 0.2857142857142857, 'recall': 0.1, 'f1-score': 0.14814814814814817, 'support': 20}\n",
      "4: {'precision': 0.35294117647058826, 'recall': 0.3157894736842105, 'f1-score': 0.33333333333333337, 'support': 19}\n",
      "5: {'precision': 0.3684210526315789, 'recall': 0.3333333333333333, 'f1-score': 0.35, 'support': 21}\n",
      "macro avg: {'precision': 0.26237871366870336, 'recall': 0.239346554792779, 'f1-score': 0.21794532627865962, 'support': 119}\n",
      "weighted avg: {'precision': 0.26693677126853493, 'recall': 0.226890756302521, 'f1-score': 0.21559512693966476, 'support': 119}\n",
      "========================================\n",
      "########################################\n",
      "########################################\n",
      "\\Class:  == Class_4 ==\n",
      "\n",
      "========================================\n",
      "Augmentation UnnamedMultiply Classification Report:\n",
      "0: {'precision': 0.2127659574468085, 'recall': 0.625, 'f1-score': 0.31746031746031744, 'support': 16}\n",
      "1: {'precision': 0.2222222222222222, 'recall': 0.08695652173913043, 'f1-score': 0.125, 'support': 23}\n",
      "2: {'precision': 0.3, 'recall': 0.3, 'f1-score': 0.3, 'support': 20}\n",
      "3: {'precision': 0.23076923076923078, 'recall': 0.15, 'f1-score': 0.18181818181818185, 'support': 20}\n",
      "4: {'precision': 0.4117647058823529, 'recall': 0.3684210526315789, 'f1-score': 0.3888888888888889, 'support': 19}\n",
      "5: {'precision': 0.38461538461538464, 'recall': 0.23809523809523808, 'f1-score': 0.2941176470588235, 'support': 21}\n",
      "macro avg: {'precision': 0.29368958348933316, 'recall': 0.29474546874432456, 'f1-score': 0.2678808392043686, 'support': 119}\n",
      "weighted avg: {'precision': 0.2943798616330458, 'recall': 0.2773109243697479, 'f1-score': 0.2618158671668311, 'support': 119}\n",
      "========================================\n",
      "Augmentation UnnamedFlipud Classification Report:\n",
      "0: {'precision': 0.14814814814814814, 'recall': 0.5, 'f1-score': 0.22857142857142856, 'support': 16}\n",
      "1: {'precision': 0.2857142857142857, 'recall': 0.08695652173913043, 'f1-score': 0.13333333333333333, 'support': 23}\n",
      "2: {'precision': 0.13333333333333333, 'recall': 0.1, 'f1-score': 0.1142857142857143, 'support': 20}\n",
      "3: {'precision': 0.2857142857142857, 'recall': 0.1, 'f1-score': 0.14814814814814817, 'support': 20}\n",
      "4: {'precision': 0.35294117647058826, 'recall': 0.3157894736842105, 'f1-score': 0.33333333333333337, 'support': 19}\n",
      "5: {'precision': 0.3684210526315789, 'recall': 0.3333333333333333, 'f1-score': 0.35, 'support': 21}\n",
      "macro avg: {'precision': 0.26237871366870336, 'recall': 0.239346554792779, 'f1-score': 0.21794532627865962, 'support': 119}\n",
      "weighted avg: {'precision': 0.26693677126853493, 'recall': 0.226890756302521, 'f1-score': 0.21559512693966476, 'support': 119}\n",
      "========================================\n",
      "Augmentation UnnamedFliplr Classification Report:\n",
      "0: {'precision': 0.24074074074074073, 'recall': 0.8125, 'f1-score': 0.3714285714285714, 'support': 16}\n",
      "1: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 23}\n",
      "2: {'precision': 0.18181818181818182, 'recall': 0.2, 'f1-score': 0.1904761904761905, 'support': 20}\n",
      "3: {'precision': 0.16666666666666666, 'recall': 0.05, 'f1-score': 0.07692307692307691, 'support': 20}\n",
      "4: {'precision': 0.35294117647058826, 'recall': 0.3157894736842105, 'f1-score': 0.33333333333333337, 'support': 19}\n",
      "5: {'precision': 0.35294117647058826, 'recall': 0.2857142857142857, 'f1-score': 0.31578947368421056, 'support': 21}\n",
      "macro avg: {'precision': 0.21585132369446094, 'recall': 0.27733395989974935, 'f1-score': 0.21465844097423045, 'support': 119}\n",
      "weighted avg: {'precision': 0.20957307462497776, 'recall': 0.25210084033613445, 'f1-score': 0.20382987202978356, 'support': 119}\n",
      "========================================\n",
      "########################################\n",
      "########################################\n",
      "\\Class:  == Class_5 ==\n",
      "\n",
      "========================================\n",
      "Augmentation UnnamedMultiply Classification Report:\n",
      "0: {'precision': 0.16981132075471697, 'recall': 0.5625, 'f1-score': 0.2608695652173913, 'support': 16}\n",
      "1: {'precision': 0.25, 'recall': 0.043478260869565216, 'f1-score': 0.07407407407407408, 'support': 23}\n",
      "2: {'precision': 0.16666666666666666, 'recall': 0.2, 'f1-score': 0.1818181818181818, 'support': 20}\n",
      "3: {'precision': 0.375, 'recall': 0.15, 'f1-score': 0.21428571428571425, 'support': 20}\n",
      "4: {'precision': 0.2857142857142857, 'recall': 0.21052631578947367, 'f1-score': 0.24242424242424243, 'support': 19}\n",
      "5: {'precision': 0.375, 'recall': 0.2857142857142857, 'f1-score': 0.3243243243243243, 'support': 21}\n",
      "macro avg: {'precision': 0.27036537885594486, 'recall': 0.24203647706222076, 'f1-score': 0.21629935035732137, 'support': 119}\n",
      "weighted avg: {'precision': 0.27398223440319525, 'recall': 0.226890756302521, 'f1-score': 0.211903916690179, 'support': 119}\n",
      "========================================\n",
      "Augmentation UnnamedFlipud Classification Report:\n",
      "0: {'precision': 0.14814814814814814, 'recall': 0.5, 'f1-score': 0.22857142857142856, 'support': 16}\n",
      "1: {'precision': 0.2857142857142857, 'recall': 0.08695652173913043, 'f1-score': 0.13333333333333333, 'support': 23}\n",
      "2: {'precision': 0.13333333333333333, 'recall': 0.1, 'f1-score': 0.1142857142857143, 'support': 20}\n",
      "3: {'precision': 0.2857142857142857, 'recall': 0.1, 'f1-score': 0.14814814814814817, 'support': 20}\n",
      "4: {'precision': 0.35294117647058826, 'recall': 0.3157894736842105, 'f1-score': 0.33333333333333337, 'support': 19}\n",
      "5: {'precision': 0.3684210526315789, 'recall': 0.3333333333333333, 'f1-score': 0.35, 'support': 21}\n",
      "macro avg: {'precision': 0.26237871366870336, 'recall': 0.239346554792779, 'f1-score': 0.21794532627865962, 'support': 119}\n",
      "weighted avg: {'precision': 0.26693677126853493, 'recall': 0.226890756302521, 'f1-score': 0.21559512693966476, 'support': 119}\n",
      "========================================\n",
      "Augmentation UnnamedFliplr Classification Report:\n",
      "0: {'precision': 0.14814814814814814, 'recall': 0.5, 'f1-score': 0.22857142857142856, 'support': 16}\n",
      "1: {'precision': 0.2857142857142857, 'recall': 0.08695652173913043, 'f1-score': 0.13333333333333333, 'support': 23}\n",
      "2: {'precision': 0.13333333333333333, 'recall': 0.1, 'f1-score': 0.1142857142857143, 'support': 20}\n",
      "3: {'precision': 0.2857142857142857, 'recall': 0.1, 'f1-score': 0.14814814814814817, 'support': 20}\n",
      "4: {'precision': 0.35294117647058826, 'recall': 0.3157894736842105, 'f1-score': 0.33333333333333337, 'support': 19}\n",
      "5: {'precision': 0.3684210526315789, 'recall': 0.3333333333333333, 'f1-score': 0.35, 'support': 21}\n",
      "macro avg: {'precision': 0.26237871366870336, 'recall': 0.239346554792779, 'f1-score': 0.21794532627865962, 'support': 119}\n",
      "weighted avg: {'precision': 0.26693677126853493, 'recall': 0.226890756302521, 'f1-score': 0.21559512693966476, 'support': 119}\n",
      "========================================\n",
      "########################################\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from imgaug import augmenters as iaa\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import warnings\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load the dataset from the CSV file\n",
    "data = pd.read_csv(\"../csv/minority_train.csv\")\n",
    "\n",
    "# Initialize variables to store sampled data as lists\n",
    "sampled_image_paths = []\n",
    "sampled_class_labels = []\n",
    "\n",
    "# Specify the number of samples per class and the total number of samples\n",
    "samples_per_class = 100  # Adjust as needed\n",
    "total_samples = 600\n",
    "\n",
    "# Iterate through unique classes\n",
    "unique_classes = data[\"dx\"].unique()\n",
    "for class_label in unique_classes:\n",
    "    # Select samples for the current class\n",
    "    class_data = data[data[\"dx\"] == class_label].head(samples_per_class)\n",
    "    \n",
    "    # Append the sampled image paths and class labels to the result lists\n",
    "    sampled_image_paths.extend(class_data[\"image_pth\"].tolist())\n",
    "    sampled_class_labels.extend(class_data[\"dx\"].tolist())\n",
    "\n",
    "\n",
    "# Initialize an empty list to store images\n",
    "images = []\n",
    "\n",
    "# Load images using OpenCV and convert to grayscale\n",
    "for image_path in sampled_image_paths:\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    images.append(image)\n",
    "\n",
    "\n",
    "X = np.array(images)  # Convert to numpy array\n",
    "\n",
    "# Convert class labels to numeric values\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(sampled_class_labels)\n",
    "\n",
    "# Flatten the image data\n",
    "X = X.reshape(X.shape[0], -1)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "print(f\"ytest: {np.unique(y_test)}\")\n",
    "print(f\"ytrain: {np.unique(y_train)}\")\n",
    "\n",
    "class_distribution_test = np.bincount(y_test)\n",
    "class_distribution_train = np.bincount(y_train)\n",
    "print(\"Class distribution in y_test:\", class_distribution_test)\n",
    "print(\"Class distribution in y_train:\", class_distribution_train)\n",
    "\n",
    "# Generate a synthetic multiclass classification dataset (you should replace this with your real data)\n",
    "# X, y = make_classification(n_samples=1000, n_features=20, n_classes=5, n_informative=5, random_state=42)\n",
    "\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = (X_train * 255).astype(np.uint8)\n",
    "X_test = (X_test * 255).astype(np.uint8)\n",
    "\n",
    "# Define a list of augmentation techniques\n",
    "augmentations = [\n",
    "    iaa.Multiply((0.5, 1.5)),  # Brightness multiplication between 0.5 and 1.5\n",
    "    iaa.Flipud(0.5),  # Vertical flip with 50% probability\n",
    "    # iaa.Affine(rotate=(-45, 45)),  # Rotation between -45 and 45 degrees\n",
    "    iaa.Fliplr(0.5),  # Horizontal flip with 50% probability\n",
    "]\n",
    "\n",
    "# Define the base classifier (Decision Tree)\n",
    "base_classifier = DecisionTreeClassifier(max_depth=1)\n",
    "\n",
    "# Initialize AdaBoostClassifier with the base classifier\n",
    "\n",
    "adaboost_classifier = AdaBoostClassifier(base_classifier, n_estimators=50, random_state=42)\n",
    "\n",
    "# Create a dictionary to store classification reports for each augmentation and class\n",
    "augmentation_reports = {}\n",
    "unique_classes_test = np.unique(y_test)\n",
    "\n",
    "\n",
    "# Train AdaBoost with each augmentation technique for each class and record classification report\n",
    "num_iterations = 10  # Number of iterations to test each augmentation\n",
    "consolidated_x = []\n",
    "consolidated_y = []\n",
    "\n",
    "for class_label in np.unique(y_train):\n",
    "    print(f\"Class: {class_label}\")\n",
    "    class_mask = (y_train == class_label)\n",
    "    other_mask = (y_train != class_label)\n",
    "    augmentation_reports[f'Class_{class_label}'] = {}\n",
    "    for augmentation in augmentations:\n",
    "        print(f'\\tAugmentation: {augmentation.name}')\n",
    "        # augmentation_reports[f'Class_{class_label}'] = {}    \n",
    "        augmented_X_train = X_train[class_mask].copy()\n",
    "        non_augmented_X_train = X_train[other_mask].copy()\n",
    "    \n",
    "        # Apply augmentation to the samples of the current class\n",
    "        augmented_X_train = augmentation.augment_images(augmented_X_train)\n",
    "    \n",
    "        # augmented should be combined with X-train left over data.\n",
    "        all_data = np.concatenate((augmented_X_train, non_augmented_X_train), axis=0)\n",
    "        all_labels = np.concatenate((y_train[class_mask], y_train[other_mask]), axis=0)\n",
    "    \n",
    "        # Fit AdaBoost classifier for the current class\n",
    "        # adaboost_classifier.fit(augmented_X_train, y_train[class_mask])\n",
    "        adaboost_classifier.fit(all_data, all_labels)\n",
    "    \n",
    "    \n",
    "        # Evaluate the classifier on the test set\n",
    "        y_pred = adaboost_classifier.predict(X_test)\n",
    "        # Check unique classes in y_test and y_pred\n",
    "        print(f'\\tClasses test : {y_test}')\n",
    "        print(f'\\tClasses pred : {y_pred}')\n",
    "        \n",
    "        # for idx in range(0, len(X_test)):\n",
    "        #     cv2.imwrite(f'./images/{y_test[idx]},{y_pred[idx]}.jpg', X_test[idx].reshape(450, 600))\n",
    "        # Then, when calling classification_report, pass the target_names parameter\n",
    "        classification_rep = classification_report(y_test, y_pred, target_names=unique_classes_test, output_dict=True)\n",
    "        print(f'\\tClassification report: {classification_rep}')\n",
    "        # Store the classification report in the dictionary with keys based on augmentation and class\n",
    "        augmentation_reports[f'Class_{class_label}'][augmentation.name] = classification_rep\n",
    "\n",
    "# Print the classification report for each augmentation technique and class\n",
    "for class_report, augmentation in augmentation_reports.items():\n",
    "    print(\"#\" * 40)\n",
    "    print(f\"\\Class:  == {class_report} ==\\n\")\n",
    "    print(\"=\" * 40)\n",
    "    for augment, report in augmentation.items():\n",
    "        print(f\"Augmentation {augment} Classification Report:\")\n",
    "        for metric, value in report.items():\n",
    "            if metric != 'accuracy':\n",
    "                # print(f\"metric: {metric}, value: {value}\")\n",
    "                print(f\"{metric}: {value:.2f}\" if isinstance(value, (float, np.float32)) else f\"{metric}: {value}\")\n",
    "        print(\"=\" * 40)\n",
    "    print(\"#\" * 40)\n",
    "\n",
    "\n",
    "with open('metrics_100_per_class.txt', 'w+')as metrics:\n",
    "   metrics.write(str(augmentation_reports))\n",
    "# print(\"*\" * 40)\n",
    "# print(class_reports)\n",
    "# print(\"*\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########################################\n",
      "\\Class:  == Class_0 ==\n",
      "\n",
      "========================================\n",
      "Augmentation UnnamedFliplr Classification Report:\n",
      "0: {'precision': 0.16666666666666666, 'recall': 0.6666666666666666, 'f1-score': 0.26666666666666666, 'support': 3}\n",
      "1: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 5}\n",
      "2: {'precision': 0.2, 'recall': 0.6666666666666666, 'f1-score': 0.30769230769230765, 'support': 3}\n",
      "3: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 3}\n",
      "4: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 5}\n",
      "5: {'precision': 0.5, 'recall': 0.2, 'f1-score': 0.28571428571428575, 'support': 5}\n",
      "macro avg: {'precision': 0.14444444444444446, 'recall': 0.25555555555555554, 'f1-score': 0.14334554334554336, 'support': 24}\n",
      "weighted avg: {'precision': 0.15, 'recall': 0.20833333333333334, 'f1-score': 0.13131868131868132, 'support': 24}\n",
      "========================================\n",
      "Augmentation UnnamedFlipud Classification Report:\n",
      "0: {'precision': 0.18181818181818182, 'recall': 0.6666666666666666, 'f1-score': 0.28571428571428575, 'support': 3}\n",
      "1: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 5}\n",
      "2: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 3}\n",
      "3: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 3}\n",
      "4: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 5}\n",
      "5: {'precision': 0.2727272727272727, 'recall': 0.6, 'f1-score': 0.37499999999999994, 'support': 5}\n",
      "macro avg: {'precision': 0.07575757575757576, 'recall': 0.2111111111111111, 'f1-score': 0.11011904761904762, 'support': 24}\n",
      "weighted avg: {'precision': 0.07954545454545454, 'recall': 0.20833333333333334, 'f1-score': 0.1138392857142857, 'support': 24}\n",
      "========================================\n",
      "Augmentation UnnamedMultiply Classification Report:\n",
      "0: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 3}\n",
      "1: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 5}\n",
      "2: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 3}\n",
      "3: {'precision': 0.16666666666666666, 'recall': 0.6666666666666666, 'f1-score': 0.26666666666666666, 'support': 3}\n",
      "4: {'precision': 1.0, 'recall': 0.6, 'f1-score': 0.7499999999999999, 'support': 5}\n",
      "5: {'precision': 0.5, 'recall': 0.2, 'f1-score': 0.28571428571428575, 'support': 5}\n",
      "macro avg: {'precision': 0.2777777777777778, 'recall': 0.24444444444444444, 'f1-score': 0.21706349206349207, 'support': 24}\n",
      "weighted avg: {'precision': 0.3333333333333333, 'recall': 0.25, 'f1-score': 0.24910714285714286, 'support': 24}\n",
      "========================================\n",
      "########################################\n",
      "########################################\n",
      "\\Class:  == Class_1 ==\n",
      "\n",
      "========================================\n",
      "Augmentation UnnamedFliplr Classification Report:\n",
      "0: {'precision': 0.18181818181818182, 'recall': 0.6666666666666666, 'f1-score': 0.28571428571428575, 'support': 3}\n",
      "1: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 5}\n",
      "2: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 3}\n",
      "3: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 3}\n",
      "4: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 5}\n",
      "5: {'precision': 0.2727272727272727, 'recall': 0.6, 'f1-score': 0.37499999999999994, 'support': 5}\n",
      "macro avg: {'precision': 0.07575757575757576, 'recall': 0.2111111111111111, 'f1-score': 0.11011904761904762, 'support': 24}\n",
      "weighted avg: {'precision': 0.07954545454545454, 'recall': 0.20833333333333334, 'f1-score': 0.1138392857142857, 'support': 24}\n",
      "========================================\n",
      "Augmentation UnnamedFlipud Classification Report:\n",
      "0: {'precision': 0.18181818181818182, 'recall': 0.6666666666666666, 'f1-score': 0.28571428571428575, 'support': 3}\n",
      "1: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 5}\n",
      "2: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 3}\n",
      "3: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 3}\n",
      "4: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 5}\n",
      "5: {'precision': 0.2727272727272727, 'recall': 0.6, 'f1-score': 0.37499999999999994, 'support': 5}\n",
      "macro avg: {'precision': 0.07575757575757576, 'recall': 0.2111111111111111, 'f1-score': 0.11011904761904762, 'support': 24}\n",
      "weighted avg: {'precision': 0.07954545454545454, 'recall': 0.20833333333333334, 'f1-score': 0.1138392857142857, 'support': 24}\n",
      "========================================\n",
      "Augmentation UnnamedMultiply Classification Report:\n",
      "0: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 3}\n",
      "1: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 5}\n",
      "2: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 3}\n",
      "3: {'precision': 0.15384615384615385, 'recall': 0.6666666666666666, 'f1-score': 0.25, 'support': 3}\n",
      "4: {'precision': 0.5, 'recall': 0.2, 'f1-score': 0.28571428571428575, 'support': 5}\n",
      "5: {'precision': 0.5, 'recall': 0.4, 'f1-score': 0.4444444444444445, 'support': 5}\n",
      "macro avg: {'precision': 0.1923076923076923, 'recall': 0.2111111111111111, 'f1-score': 0.16335978835978837, 'support': 24}\n",
      "weighted avg: {'precision': 0.22756410256410256, 'recall': 0.20833333333333334, 'f1-score': 0.18336640211640212, 'support': 24}\n",
      "========================================\n",
      "########################################\n",
      "########################################\n",
      "\\Class:  == Class_2 ==\n",
      "\n",
      "========================================\n",
      "Augmentation UnnamedFliplr Classification Report:\n",
      "0: {'precision': 0.18181818181818182, 'recall': 0.6666666666666666, 'f1-score': 0.28571428571428575, 'support': 3}\n",
      "1: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 5}\n",
      "2: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 3}\n",
      "3: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 3}\n",
      "4: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 5}\n",
      "5: {'precision': 0.2727272727272727, 'recall': 0.6, 'f1-score': 0.37499999999999994, 'support': 5}\n",
      "macro avg: {'precision': 0.07575757575757576, 'recall': 0.2111111111111111, 'f1-score': 0.11011904761904762, 'support': 24}\n",
      "weighted avg: {'precision': 0.07954545454545454, 'recall': 0.20833333333333334, 'f1-score': 0.1138392857142857, 'support': 24}\n",
      "========================================\n",
      "Augmentation UnnamedFlipud Classification Report:\n",
      "0: {'precision': 0.18181818181818182, 'recall': 0.6666666666666666, 'f1-score': 0.28571428571428575, 'support': 3}\n",
      "1: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 5}\n",
      "2: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 3}\n",
      "3: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 3}\n",
      "4: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 5}\n",
      "5: {'precision': 0.2727272727272727, 'recall': 0.6, 'f1-score': 0.37499999999999994, 'support': 5}\n",
      "macro avg: {'precision': 0.07575757575757576, 'recall': 0.2111111111111111, 'f1-score': 0.11011904761904762, 'support': 24}\n",
      "weighted avg: {'precision': 0.07954545454545454, 'recall': 0.20833333333333334, 'f1-score': 0.1138392857142857, 'support': 24}\n",
      "========================================\n",
      "Augmentation UnnamedMultiply Classification Report:\n",
      "0: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 3}\n",
      "1: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 5}\n",
      "2: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 3}\n",
      "3: {'precision': 0.15384615384615385, 'recall': 0.6666666666666666, 'f1-score': 0.25, 'support': 3}\n",
      "4: {'precision': 0.6, 'recall': 0.6, 'f1-score': 0.6, 'support': 5}\n",
      "5: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 5}\n",
      "macro avg: {'precision': 0.12564102564102564, 'recall': 0.2111111111111111, 'f1-score': 0.14166666666666666, 'support': 24}\n",
      "weighted avg: {'precision': 0.14423076923076925, 'recall': 0.20833333333333334, 'f1-score': 0.15625, 'support': 24}\n",
      "========================================\n",
      "########################################\n",
      "########################################\n",
      "\\Class:  == Class_3 ==\n",
      "\n",
      "========================================\n",
      "Augmentation UnnamedFliplr Classification Report:\n",
      "0: {'precision': 0.18181818181818182, 'recall': 0.6666666666666666, 'f1-score': 0.28571428571428575, 'support': 3}\n",
      "1: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 5}\n",
      "2: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 3}\n",
      "3: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 3}\n",
      "4: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 5}\n",
      "5: {'precision': 0.2727272727272727, 'recall': 0.6, 'f1-score': 0.37499999999999994, 'support': 5}\n",
      "macro avg: {'precision': 0.07575757575757576, 'recall': 0.2111111111111111, 'f1-score': 0.11011904761904762, 'support': 24}\n",
      "weighted avg: {'precision': 0.07954545454545454, 'recall': 0.20833333333333334, 'f1-score': 0.1138392857142857, 'support': 24}\n",
      "========================================\n",
      "Augmentation UnnamedFlipud Classification Report:\n",
      "0: {'precision': 0.18181818181818182, 'recall': 0.6666666666666666, 'f1-score': 0.28571428571428575, 'support': 3}\n",
      "1: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 5}\n",
      "2: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 3}\n",
      "3: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 3}\n",
      "4: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 5}\n",
      "5: {'precision': 0.2727272727272727, 'recall': 0.6, 'f1-score': 0.37499999999999994, 'support': 5}\n",
      "macro avg: {'precision': 0.07575757575757576, 'recall': 0.2111111111111111, 'f1-score': 0.11011904761904762, 'support': 24}\n",
      "weighted avg: {'precision': 0.07954545454545454, 'recall': 0.20833333333333334, 'f1-score': 0.1138392857142857, 'support': 24}\n",
      "========================================\n",
      "Augmentation UnnamedMultiply Classification Report:\n",
      "0: {'precision': 0.14285714285714285, 'recall': 0.6666666666666666, 'f1-score': 0.23529411764705882, 'support': 3}\n",
      "1: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 5}\n",
      "2: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 3}\n",
      "3: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 3}\n",
      "4: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 5}\n",
      "5: {'precision': 0.3333333333333333, 'recall': 0.6, 'f1-score': 0.42857142857142855, 'support': 5}\n",
      "macro avg: {'precision': 0.07936507936507936, 'recall': 0.2111111111111111, 'f1-score': 0.11064425770308123, 'support': 24}\n",
      "weighted avg: {'precision': 0.08730158730158728, 'recall': 0.20833333333333334, 'f1-score': 0.11869747899159662, 'support': 24}\n",
      "========================================\n",
      "########################################\n",
      "########################################\n",
      "\\Class:  == Class_4 ==\n",
      "\n",
      "========================================\n",
      "Augmentation UnnamedFliplr Classification Report:\n",
      "0: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 3}\n",
      "1: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 5}\n",
      "2: {'precision': 0.2, 'recall': 1.0, 'f1-score': 0.33333333333333337, 'support': 3}\n",
      "3: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 3}\n",
      "4: {'precision': 1.0, 'recall': 0.2, 'f1-score': 0.33333333333333337, 'support': 5}\n",
      "5: {'precision': 0.4, 'recall': 0.4, 'f1-score': 0.4000000000000001, 'support': 5}\n",
      "macro avg: {'precision': 0.26666666666666666, 'recall': 0.26666666666666666, 'f1-score': 0.1777777777777778, 'support': 24}\n",
      "weighted avg: {'precision': 0.31666666666666665, 'recall': 0.25, 'f1-score': 0.1944444444444445, 'support': 24}\n",
      "========================================\n",
      "Augmentation UnnamedFlipud Classification Report:\n",
      "0: {'precision': 0.18181818181818182, 'recall': 0.6666666666666666, 'f1-score': 0.28571428571428575, 'support': 3}\n",
      "1: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 5}\n",
      "2: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 3}\n",
      "3: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 3}\n",
      "4: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 5}\n",
      "5: {'precision': 0.2727272727272727, 'recall': 0.6, 'f1-score': 0.37499999999999994, 'support': 5}\n",
      "macro avg: {'precision': 0.07575757575757576, 'recall': 0.2111111111111111, 'f1-score': 0.11011904761904762, 'support': 24}\n",
      "weighted avg: {'precision': 0.07954545454545454, 'recall': 0.20833333333333334, 'f1-score': 0.1138392857142857, 'support': 24}\n",
      "========================================\n",
      "Augmentation UnnamedMultiply Classification Report:\n",
      "0: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 3}\n",
      "1: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 5}\n",
      "2: {'precision': 0.09523809523809523, 'recall': 0.6666666666666666, 'f1-score': 0.16666666666666666, 'support': 3}\n",
      "3: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 3}\n",
      "4: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 5}\n",
      "5: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 5}\n",
      "macro avg: {'precision': 0.015873015873015872, 'recall': 0.1111111111111111, 'f1-score': 0.027777777777777776, 'support': 24}\n",
      "weighted avg: {'precision': 0.011904761904761904, 'recall': 0.08333333333333333, 'f1-score': 0.020833333333333332, 'support': 24}\n",
      "========================================\n",
      "########################################\n",
      "########################################\n",
      "\\Class:  == Class_5 ==\n",
      "\n",
      "========================================\n",
      "Augmentation UnnamedFliplr Classification Report:\n",
      "0: {'precision': 0.18181818181818182, 'recall': 0.6666666666666666, 'f1-score': 0.28571428571428575, 'support': 3}\n",
      "1: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 5}\n",
      "2: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 3}\n",
      "3: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 3}\n",
      "4: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 5}\n",
      "5: {'precision': 0.2727272727272727, 'recall': 0.6, 'f1-score': 0.37499999999999994, 'support': 5}\n",
      "macro avg: {'precision': 0.07575757575757576, 'recall': 0.2111111111111111, 'f1-score': 0.11011904761904762, 'support': 24}\n",
      "weighted avg: {'precision': 0.07954545454545454, 'recall': 0.20833333333333334, 'f1-score': 0.1138392857142857, 'support': 24}\n",
      "========================================\n",
      "Augmentation UnnamedFlipud Classification Report:\n",
      "0: {'precision': 0.18181818181818182, 'recall': 0.6666666666666666, 'f1-score': 0.28571428571428575, 'support': 3}\n",
      "1: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 5}\n",
      "2: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 3}\n",
      "3: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 3}\n",
      "4: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 5}\n",
      "5: {'precision': 0.2727272727272727, 'recall': 0.6, 'f1-score': 0.37499999999999994, 'support': 5}\n",
      "macro avg: {'precision': 0.07575757575757576, 'recall': 0.2111111111111111, 'f1-score': 0.11011904761904762, 'support': 24}\n",
      "weighted avg: {'precision': 0.07954545454545454, 'recall': 0.20833333333333334, 'f1-score': 0.1138392857142857, 'support': 24}\n",
      "========================================\n",
      "Augmentation UnnamedMultiply Classification Report:\n",
      "0: {'precision': 0.13636363636363635, 'recall': 1.0, 'f1-score': 0.24000000000000002, 'support': 3}\n",
      "1: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 5}\n",
      "2: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 3}\n",
      "3: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 3}\n",
      "4: {'precision': 1.0, 'recall': 0.2, 'f1-score': 0.33333333333333337, 'support': 5}\n",
      "5: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 5}\n",
      "macro avg: {'precision': 0.18939393939393936, 'recall': 0.19999999999999998, 'f1-score': 0.09555555555555556, 'support': 24}\n",
      "weighted avg: {'precision': 0.22537878787878787, 'recall': 0.16666666666666666, 'f1-score': 0.09944444444444446, 'support': 24}\n",
      "========================================\n",
      "########################################\n"
     ]
    }
   ],
   "source": [
    "for class_report, augmentation in augmentation_reports.items():\n",
    "    print(\"#\" * 40)\n",
    "    print(f\"\\Class:  == {class_report} ==\\n\")\n",
    "    print(\"=\" * 40)\n",
    "    for augment, report in augmentation.items():\n",
    "        print(f\"Augmentation {augment} Classification Report:\")\n",
    "        for metric, value in report.items():\n",
    "            if metric != 'accuracy':\n",
    "                # print(f\"metric: {metric}, value: {value}\")\n",
    "                print(f\"{metric}: {value:.2f}\" if isinstance(value, (float, np.float32)) else f\"{metric}: {value}\")\n",
    "        print(\"=\" * 40)\n",
    "    print(\"#\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('metrics.txt', 'w+')as metrics:\n",
    "   metrics.write(str(augmentation_reports))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset from the CSV file\n",
    "data = pd.read_csv(\"../csv/minority_train.csv\")\n",
    "\n",
    "sampled_image_paths = []\n",
    "sampled_class_labels = []\n",
    "samples_per_class = 100  # Adjust as needed\n",
    "total_samples = 600\n",
    "\n",
    "unique_classes = data[\"dx\"].unique()\n",
    "for class_label in unique_classes:\n",
    "    class_data = data[data[\"dx\"] == class_label].head(samples_per_class)\n",
    "    sampled_image_paths.extend(class_data[\"image_pth\"].tolist())\n",
    "    sampled_class_labels.extend(class_data[\"dx\"].tolist())\n",
    "images = []\n",
    "\n",
    "for image_path in sampled_image_paths:\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    images.append(image)\n",
    "\n",
    "X = np.array(images)  # Convert to numpy array\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(sampled_class_labels)\n",
    "\n",
    "X = X.reshape(X.shape[0], -1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(f\"ytest: {np.unique(y_test)}\")\n",
    "print(f\"ytrain: {np.unique(y_train)}\")\n",
    "\n",
    "class_distribution_test = np.bincount(y_test)\n",
    "class_distribution_train = np.bincount(y_train)\n",
    "print(\"Class distribution in y_test:\", class_distribution_test)\n",
    "print(\"Class distribution in y_train:\", class_distribution_train)\n",
    "\n",
    "X_train = (X_train * 255).astype(np.uint8)\n",
    "X_test = (X_test * 255).astype(np.uint8)\n",
    "\n",
    "# Define a list of augmentation techniques\n",
    "augmentation = iaa.Fliplr(0.5),  # Horizontal flip with 50% probability\n",
    "\n",
    "base_classifier = DecisionTreeClassifier(max_depth=1)\n",
    "adaboost_classifier = AdaBoostClassifier(base_classifier, n_estimators=50, random_state=42)\n",
    "augmentation_reports = {}\n",
    "unique_classes_test = np.unique(y_test)\n",
    "num_iterations = 10  # Number of iterations to test each augmentation\n",
    "consolidated_x = []\n",
    "consolidated_y = []\n",
    "\n",
    "for class_label in np.unique(y_train):\n",
    "    print(f\"Class: {class_label}\")\n",
    "    class_mask = (y_train == class_label)\n",
    "    other_mask = (y_train != class_label)\n",
    "    augmentation_reports[f'Class_{class_label}'] = {}\n",
    "    augmented_X_train = X_train[class_mask].copy()\n",
    "    non_augmented_X_train = X_train[other_mask].copy()\n",
    "    augmented_X_train = augmentation.augment_images(augmented_X_train)\n",
    "    all_data = np.concatenate((augmented_X_train, non_augmented_X_train), axis=0)\n",
    "    all_labels = np.concatenate((y_train[class_mask], y_train[other_mask]), axis=0)\n",
    "    adaboost_classifier.fit(all_data, all_labels)\n",
    "    y_pred = adaboost_classifier.predict(X_test)\n",
    "    print(f'Classes test : {y_test}')\n",
    "    print(f'Classes pred : {y_pred}')\n",
    "    classification_rep = classification_report(y_test, y_pred, target_names=unique_classes_test, output_dict=True)\n",
    "    augmentation_reports[f'Class_{class_label}'] = classification_rep\n",
    "\n",
    "# Print the classification report for each augmentation technique and class\n",
    "for class_report, augmentation in augmentation_reports.items():\n",
    "    print(\"#\" * 40)\n",
    "    print(f\"\\Class:  == {class_report} ==\\n\")\n",
    "    print(\"=\" * 40)\n",
    "    for augment, report in augmentation.items():\n",
    "        print(f\"Augmentation {augment} Classification Report:\")\n",
    "        for metric, value in report.items():\n",
    "            if metric != 'accuracy':\n",
    "                # print(f\"metric: {metric}, value: {value}\")\n",
    "                print(f\"{metric}: {value:.2f}\" if isinstance(value, (float, np.float32)) else f\"{metric}: {value}\")\n",
    "        print(\"=\" * 40)\n",
    "    print(\"#\" * 40)\n",
    "\n",
    "with open('metrics_100_per_class.txt', 'w+')as metrics:\n",
    "    metrics.write(str(augmentation_reports))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
