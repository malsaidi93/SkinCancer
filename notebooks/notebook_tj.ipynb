{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import matplotlib as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(path):\n",
    "    meta = pd.read_csv(path, index_col=False)\n",
    "    return meta\n",
    "\n",
    "# meta = read_file(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta  = read_file('../data/Aug2.0_Meta_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '../data/Aug2.0/'\n",
    "file_path = '../data/new_augmented.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta['new_paths'] = root + meta['image_id']+'.jpg'\n",
    "meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "X, y = meta.iloc[:,[0,1,3,4,5,6,7]], meta.iloc[:,2]\n",
    "\n",
    "# train/test Split\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(X, y, test_size=0.20, stratify=y)\n",
    "print(f\"train: {len(xtrain)}, test: {len(xtest)} \")\n",
    "\n",
    "# Concat X/y for train/test\n",
    "xtrain.insert(loc = 2, column = 'dx', value = ytrain)\n",
    "xtest.insert(loc= 2 , column = 'dx', value = ytest )\n",
    "\n",
    "# Writing to CSV\n",
    "xtest.to_csv('../data/Aug2.0_test.csv', index=False)\n",
    "xtrain.to_csv('../data/Aug2.0_train.csv', index=False)\n",
    "\n",
    "xtrain['dx'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Check_Paths(file):\n",
    "    meta = pd.read_csv(file)\n",
    "    Files_NotFound = []\n",
    "    for i, r in meta.iterrows():\n",
    "        if os.path.exists(meta.iloc[i, -1]):\n",
    "            continue\n",
    "        else:\n",
    "            Files_NotFound.append(meta.iloc[i, -1])\n",
    "    return Files_NotFound\n",
    "\n",
    "nf = Check_Paths('../data/Aug2.0_test.csv')\n",
    "len(nf)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/HAM10k/HAM10000_metadata.csv'\n",
    "def read_file(path):\n",
    "    meta = pd.read_csv(path, index_col=False)\n",
    "    return meta\n",
    "\n",
    "df = read_file(path)\n",
    "desc = df['dx'].value_counts()\n",
    "desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "gen = ImageDataGenerator(rotation_range=10, width_shift_range=0.1, height_shift_range=0.1, \n",
    "                        zoom_range= 0.1, horizontal_flip= True, rescale=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_dir = 'Aug2.0'\n",
    "basedir = '../data/HAM10k/HAM10000_images/'\n",
    "print(f\"Folder Exists..\") if os.path.exists('../data/'+aug_dir) else os.mkdir('../data/'+aug_dir)\n",
    "save_dir = '../data/'+aug_dir+'/'\n",
    "total_generated_images = 0\n",
    "for key in desc.keys():\n",
    "    print(key, desc[key])\n",
    "    ratio = int(desc['nv']/ desc[key])\n",
    "    print('Ratio to NV: ', ratio)\n",
    "    print('Augmenataions Needed/Image', ratio)\n",
    "    total_generated_images += ratio\n",
    "    all_images = df[df['dx'] == key]['image_id'].values\n",
    "    if(key == 'nv'):\n",
    "        continue\n",
    "    printonce= True\n",
    "    # iterate over all images augment them, save them and insert them in our metadata frame\n",
    "    for image_ in tqdm(all_images):\n",
    "        if(len(df[df['dx'] == key]) > len(df[df['dx'] == 'nv'])):\n",
    "            if printonce:\n",
    "                print(key, 'datapoints = ', len(df[df['dx'] == key]), 'reached above nv skipping more augmentations..')\n",
    "                printonce = False\n",
    "            continue\n",
    "    \n",
    "        image_path =  basedir + image_ + '.jpg'\n",
    "        image = load_img(image_path)\n",
    "        image = np.expand_dims(img_to_array(image), axis= 0)\n",
    "        generated = gen.flow(image)\n",
    "        row = df[df['image_id'] == image_]\n",
    "        dict_for_df = {\n",
    "            'lesion_id':row.lesion_id.values[0], 'image_id':row.image_id.values[0], \n",
    "            'dx':row.dx.values[0], 'dx_type':row.dx_type.values[0] ,\n",
    "            'age':row.age.values[0], 'sex':row.sex.values[0], 'localization':row.localization.values[0] \n",
    "        }\n",
    "       \n",
    "        for i in range(int(ratio)):\n",
    "            aug_image= next(generated).astype(np.uint8)\n",
    "            # save this image with an underscore\n",
    "            # add this to metadata dataframe\n",
    "            image_name= dict_for_df['image_id'] + '_' + str(i)\n",
    "            fname = image_name.split('_')\n",
    "            modify_name = fname[0]+'_'+fname[1]+'_'+fname[-1]\n",
    "            dict_for_df['image_id'] = modify_name\n",
    "            df = df.append(dict_for_df, ignore_index=True)\n",
    "            plt.imsave(save_dir + modify_name + '.jpg', aug_image[0])\n",
    "    \n",
    "print(f\"Total Images generated : {(total_generated_images)}\")\n",
    "print(f\"Consolidating All Images...\")\n",
    "\n",
    "# rename the images\n",
    "print(f\"Renaming files to desired format...\")\n",
    "for file in tqdm(os.listdir(save_dir)):\n",
    "    filename = file.split('_')\n",
    "    renamed = filename[0]+'_'+filename[1]+'_'+filename[-1]\n",
    "    os.rename(save_dir+file, save_dir+renamed)\n",
    "\n",
    "#  Copy the images\n",
    "for file in tqdm(os.listdir(basedir)):\n",
    "    shutil.copy(basedir+file, save_dir)\n",
    "    \n",
    "print(f\"Total Images: {len(os.listdir(save_dir))}\")\n",
    "# Modify and save the meta file\n",
    "try:\n",
    "    new_meta_file = f'{aug_dir}_Meta_all.csv'\n",
    "    # df['new_image_id'] = df['image_id'].split()\n",
    "    df.to_csv('../data/'+new_meta_file, index=False)\n",
    "    print(f\"New Meta File : {new_meta_file}\")\n",
    "except:\n",
    "    print(f\"FileError :: Error occured during meta file saving...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -L https://github.com/pablonm3/gan_skin_cancer/blob/master/skin_cancer_data_gan.ipynb -o test.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Renaming he files\n",
    "root = '../data/Aug2.0/'\n",
    "for file in os.listdir('../data/Aug2.0/'):\n",
    "    filename = file.split('_')\n",
    "    if len(filename) > 2:\n",
    "        renamed = filename[0]+'_'+filename[-1]\n",
    "    else:\n",
    "        renamed = file\n",
    "    os.rename(root + file, root + str(renamed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/Aug2.0_Meta_All.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "arr = np.array([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mustafa\\miniforge3\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<contextlib.ExitStack at 0x15033d63d00>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from os import path\n",
    "import sys\n",
    "sys.path.append(path.abspath('../src/'))\n",
    "\n",
    "from dataset import SkinCancer\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#disable interactive plotting \n",
    "plt.ioff()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs=100\n",
    "# batch_size = 64\n",
    "lr=0.0002\n",
    "b1=0.5\n",
    "b2=0.999\n",
    "n_cpu=8\n",
    "latent_dim=100\n",
    "n_classes=6\n",
    "img_size=224\n",
    "channels=1\n",
    "sample_interval=400\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init_normal(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find(\"Conv\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find(\"BatchNorm2d\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias.data, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.label_emb = nn.Embedding(n_classes, latent_dim)\n",
    "\n",
    "        self.init_size = img_size // 4  # Initial size before upsampling\n",
    "        self.l1 = nn.Sequential(nn.Linear(latent_dim, 128 * self.init_size ** 2))\n",
    "\n",
    "        self.conv_blocks = nn.Sequential(\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(128, 128, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128, 0.8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(128, 64, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64, 0.8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64, 3, 3, stride=1, padding=1),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, noise, labels):\n",
    "        gen_input = torch.mul(self.label_emb(labels), noise)\n",
    "        out = self.l1(gen_input)\n",
    "        out = out.view(out.shape[0], 128, self.init_size, self.init_size)\n",
    "        img = self.conv_blocks(out)\n",
    "        return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        def discriminator_block(in_filters, out_filters, bn=True):\n",
    "            \"\"\"Returns layers of each discriminator block\"\"\"\n",
    "            block = [nn.Conv2d(in_filters, out_filters, 3, 2, 1), nn.LeakyReLU(0.2, inplace=True), nn.Dropout2d(0.25)]\n",
    "            if bn:\n",
    "                block.append(nn.BatchNorm2d(out_filters, 0.8))\n",
    "            return block\n",
    "\n",
    "        self.conv_blocks = nn.Sequential(\n",
    "            *discriminator_block(3, 16, bn=False),\n",
    "            *discriminator_block(16, 32),\n",
    "            *discriminator_block(32, 64),\n",
    "            *discriminator_block(64, 128),\n",
    "        )\n",
    "\n",
    "        # The height and width of downsampled image\n",
    "        ds_size = img_size // 2 ** 4\n",
    "\n",
    "        # Output layers\n",
    "        self.adv_layer = nn.Sequential(nn.Linear(128 * ds_size ** 2, 1), nn.Sigmoid())\n",
    "        self.aux_layer = nn.Sequential(nn.Linear(128 * ds_size ** 2, n_classes), nn.Softmax())\n",
    "\n",
    "    def forward(self, img):\n",
    "        out = self.conv_blocks(img)\n",
    "        out = out.view(out.shape[0], -1)\n",
    "        validity = self.adv_layer(out)\n",
    "        label = self.aux_layer(out)\n",
    "\n",
    "        return validity, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (conv_blocks): Sequential(\n",
       "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (2): Dropout2d(p=0.25, inplace=False)\n",
       "    (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (5): Dropout2d(p=0.25, inplace=False)\n",
       "    (6): BatchNorm2d(32, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (8): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (9): Dropout2d(p=0.25, inplace=False)\n",
       "    (10): BatchNorm2d(64, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (12): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (13): Dropout2d(p=0.25, inplace=False)\n",
       "    (14): BatchNorm2d(128, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (adv_layer): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=1, bias=True)\n",
       "    (1): Sigmoid()\n",
       "  )\n",
       "  (aux_layer): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=6, bias=True)\n",
       "    (1): Softmax(dim=None)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loss functions\n",
    "adversarial_loss = torch.nn.BCELoss()\n",
    "auxiliary_loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Initialize generator and discriminator\n",
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "if device == 'cuda':\n",
    "    generator.cuda()\n",
    "    discriminator.cuda()\n",
    "    adversarial_loss.cuda()\n",
    "    auxiliary_loss.cuda()\n",
    "\n",
    "# Initialize weights\n",
    "generator.apply(weights_init_normal)\n",
    "discriminator.apply(weights_init_normal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Skin Cancer Dataset\n",
    "data_dir = '../data/HAM10k/HAM10000_images/'\n",
    "train_data = SkinCancer(data_dir, '../data/minority_train.csv', transform=None)\n",
    "dataset_size = len(train_data)    \n",
    "test_data = SkinCancer(data_dir, '../data/minority_test.csv',transform=None)\n",
    "classes=np.unique(train_data.classes)\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(train_data, batch_size=16)\n",
    "\n",
    "unnormalize =transforms.Normalize((-0.5 / 0.5), (1.0 / 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i,l = train_data.__getitem__(1)\n",
    "i.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.class_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizers\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=lr, betas=(b1, b2))\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(b1, b2))\n",
    "\n",
    "FloatTensor = torch.cuda.FloatTensor if device == 'cuda' else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if device == 'cuda' else torch.LongTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sample_imgs(gen_imgs,gen_labels,epoch):\n",
    "    \"\"\"Saves a grid of generated digits ranging from 0 to n_classes\"\"\"\n",
    "    # Sample noise\n",
    "    imgs = [i.detach().cpu().squeeze().permute(1,2,0) for i in gen_imgs]\n",
    "    imgs = [unnormalize(i) for i in imgs]\n",
    "    gen_lab = [int(i.detach().cpu().numpy().tolist()) for i in gen_labels]\n",
    "    titles = [train_data.class_id[i] for i in gen_lab]\n",
    "    # fig = plt.figure(figsize=(12, 8))\n",
    "    f, axes = plt.subplots(4,4,figsize=(12,10))\n",
    "    \n",
    "    for idx,img in enumerate(imgs):\n",
    "        i = idx % 4\n",
    "        j = idx // 4\n",
    "        axes[i,j].imshow(img);\n",
    "        plt.subplots_adjust(wspace=.3, hspace=0.3)\n",
    "        # a = fig.add_subplot(4, 4, i+1)\n",
    "        # imgplot = plt.plot(imgs[i])\n",
    "        # a.axis(\"off\")\n",
    "        # axes[i,j].set_title(titles[idx], fontsize=10, fontweight=\"bold\")\n",
    "    plt.savefig(f'../save/epoch_{epoch+1}_generated_batch.jpg', bbox_inches='tight')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ----------\n",
    "#  Training\n",
    "# ----------\n",
    "gen_loss = 100.0\n",
    "dis_loss = 100.0\n",
    "device='cuda'\n",
    "for epoch in range(n_epochs):\n",
    "    for i, (imgs, labels) in enumerate(dataloader):\n",
    "        \n",
    "        if i<165:\n",
    "        \n",
    "            batch_size = 16\n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Adversarial ground truths\n",
    "            valid = Variable(FloatTensor(batch_size, 1).fill_(1.0), requires_grad=False)\n",
    "            fake = Variable(FloatTensor(batch_size, 1).fill_(0.0), requires_grad=False)\n",
    "\n",
    "            # Configure input\n",
    "            # real_imgs = Variable(imgs.type(FloatTensor))\n",
    "            # labels = Variable(labels.type(LongTensor))\n",
    "\n",
    "            real_imgs = imgs\n",
    "            labels = LongTensor(labels)\n",
    "            # -----------------\n",
    "            #  Train Generator\n",
    "            # -----------------\n",
    "\n",
    "            optimizer_G.zero_grad()\n",
    "\n",
    "            # Sample noise and labels as generator input\n",
    "            z = Variable(FloatTensor(np.random.normal(0, 1, (batch_size, latent_dim))))\n",
    "            gen_labels = Variable(LongTensor(np.random.randint(0, n_classes, batch_size)))\n",
    "\n",
    "            # Generate a batch of images\n",
    "            gen_imgs = generator(z, gen_labels)\n",
    "\n",
    "            # Loss measures generator's ability to fool the discriminator\n",
    "            validity, pred_label = discriminator(gen_imgs)\n",
    "            g_loss = 0.5 * (adversarial_loss(validity, valid) + auxiliary_loss(pred_label, gen_labels))\n",
    "\n",
    "            g_loss.backward()\n",
    "            optimizer_G.step()\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Discriminator\n",
    "            # ---------------------\n",
    "\n",
    "            optimizer_D.zero_grad()\n",
    "\n",
    "            # Loss for real images\n",
    "            real_pred, real_aux = discriminator(real_imgs)\n",
    "            d_real_loss = (adversarial_loss(real_pred, valid) + auxiliary_loss(real_aux, labels)) / 2\n",
    "\n",
    "            # Loss for fake images\n",
    "            fake_pred, fake_aux = discriminator(gen_imgs.detach())\n",
    "            d_fake_loss = (adversarial_loss(fake_pred, fake) + auxiliary_loss(fake_aux, gen_labels)) / 2\n",
    "\n",
    "            # Total discriminator loss\n",
    "            d_loss = (d_real_loss + d_fake_loss) / 2\n",
    "\n",
    "            # Calculate discriminator accuracy\n",
    "            pred = np.concatenate([real_aux.data.cpu().numpy(), fake_aux.data.cpu().numpy()], axis=0)\n",
    "            gt = np.concatenate([labels.data.cpu().numpy(), gen_labels.data.cpu().numpy()], axis=0)\n",
    "            d_acc = np.mean(np.argmax(pred, axis=1) == gt)\n",
    "\n",
    "            d_loss.backward()\n",
    "            optimizer_D.step()\n",
    "            \n",
    "            if g_loss.item() < gen_loss:\n",
    "                gen_loss = g_loss.item()\n",
    "                torch.save(generator.state_dict(), f'../models/GAN/{generator._get_name()}.pth')\n",
    "                \n",
    "            if d_loss.item() < dis_loss:\n",
    "                dis_loss = d_loss.item()\n",
    "                torch.save(discriminator.state_dict(), f'../models/GAN/{discriminator._get_name()}.pth')\n",
    "            \n",
    "    \n",
    "    sample_imgs(gen_imgs,gen_labels,epoch)\n",
    "    print(\n",
    "        \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f, acc: %d%%] [G loss: %f]\"\n",
    "        % (epoch, n_epochs, i, len(dataloader), d_loss.item(), 100 * d_acc, g_loss.item())\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_imgs(gen_imgs,gen_labels,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
